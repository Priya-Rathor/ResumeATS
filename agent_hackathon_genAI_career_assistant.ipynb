{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1af5c8-b759-41c8-b813-62b4512f1276",
   "metadata": {},
   "source": [
    "# GenAI Career Assistant Agent â€“ Your Ultimate Guide to a Career in Generative AI!ðŸš€\n",
    "<a href=\"https://colab.research.google.com/drive/19lYWHVgRSSyY84HW3WkwJ9OFAA25T8KW?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "## Overview\n",
    "Meet the GenAI Career Assistantâ€”an AI-powered mentor designed to simplify and support your journey in Generative AI learning, Resume preparation, Interview assistant and job hunting.\n",
    "#### Tech Stack\n",
    "I have used all free Open source.<br>\n",
    "Langchain,Langgraph, Gemini LLM, DuckDuckGoSearchResult\n",
    "\n",
    "## Motivation\n",
    "As GenAI rapidly evolves, more people are eager to learn it for career advancement or transition. However, navigating the vast resources on the internet and platforms like YouTube can be overwhelming, with long videos and scattered, outdated materials making it hard to know where to begin in this busy life. Even using ChatGPT for coding help often yields deprecated code, as GenAI packages and methodsâ€”such as LangChain, LlamaIndex, and Hugging Faceâ€”are updated frequently.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Learning & Content Creation:**\n",
    "   - Offers tailored learning pathways in GenAI, covering key topics and skills.\n",
    "   - Assists users in creating tutorials, blogs, and posts based on their interests or queries.\n",
    "2. **Q&A Support:**\n",
    "   - Provides on-demand Q&A sessions for users needing guidance on concepts or coding issues.\n",
    "3. **Resume Building & Review:**\n",
    "   - One-on-one resume consultations and guidance.\n",
    "   - Crafts personalized, market-relevant resumes optimized for current job trends.\n",
    "4. **Interview Preparation:**\n",
    "   - Hosts Q&A sessions on common and technical interview questions.\n",
    "   - Simulates real interview scenarios and conducts mock interviews.\n",
    "5. **Job Search Assistance:**\n",
    "   - Guides users through the job search process, offering tailored insights and support. \n",
    "With the GenAI Career Assistant, your journey to a career in Generative AI becomes organized, personalized, and efficient!\n",
    "\n",
    "<img src=\"https://i.imghippo.com/files/xrJV7042k.png\" alt=\"agent\" border=\"0\" style=\"height:20%;width:90%\">\n",
    "\n",
    "## Key Components\n",
    "1. **State Management**: Using TypedDict to define and manage the state of each customer interaction.\n",
    "2. **Query Categorization**: Classifying users queries into Learning, Resume Preparation, Interview or Job Search.\n",
    "3. **Sub Categorization**: Learning(Tutorial, Q&A), Interview(Interview prep,Mock interview).\n",
    "4. **Response Generation**: Creating appropriate responses based on the query category. Create .md files for Tutorial Blogs, Resume, Mock interview etc.\n",
    "6. **Workflow Graph**: Utilizing LangGraph to create a flexible and extensible workflow.\n",
    "\n",
    "## Method Details\n",
    "1. **Initialization**: Set up the environment and import necessary libraries.\n",
    "2. **State Definition**: Create a structure to hold query information, category, sub-category, and response.\n",
    "3. **Node Functions**: Implement separate functions for categorization, and response generation.\n",
    "4. **Graph Construction**: Use StateGraph to define the workflow, adding nodes and edges to represent the support process.\n",
    "5. **Conditional Routing**: Implement logic to route queries based on their category and sub- category.\n",
    "6. **Workflow Compilation**: Compile the graph into an executable application.\n",
    "7. **Execution**: Process users queries through the workflow and retrieve results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59364b3-4120-473c-8ffd-b2492a3307bd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The GenAI Career Assistant is more than just a tool; itâ€™s a comprehensive, personalized mentor designed to help you thrive in the rapidly evolving field of Generative AI. From mastering key concepts and building a strong resume to preparing for interviews and navigating the job market, this assistant equips you with everything you need to achieve your career goals. With GenAI Career Assistant by your side, your path to a successful Generative AI career becomes clearer, more manageable, and achievable. Embrace the future of AI with confidence and step into your dream role!\n",
    "## Future Enhancement\n",
    "- **Knowledge Base**: Incorporate a resource-rich library with curated links to courses, tutorials, and articles for comprehensive learning support.\n",
    "- **Multi-Domain Customization**: Expand beyond Generative AI, allowing users to tailor the assistant to any career path, creating a versatile \"Dream Job Assistant\"\n",
    "- **Advanced Job Search Tools**: Include an automated job application tracker, enhanced networking features, and guidance on global job opportunities and visas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c313380-e8dd-4c39-b4e9-a520aa07f1c6",
   "metadata": {},
   "source": [
    "### Before starting please install the below packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e45f49d-cdc2-4b2a-a530-87adc9489e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.3.7\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.3.7\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_google_genai==2.0.4\n",
      "  Downloading langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting duckduckgo_search==6.3.4\n",
      "  Downloading duckduckgo_search-6.3.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langgraph==0.2.48\n",
      "  Downloading langgraph-0.2.48-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dotenv in d:\\projects\\resumeats\\venv\\lib\\site-packages (1.1.1)\n",
      "Collecting PyYAML>=5.3 (from langchain==0.3.7)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.7)\n",
      "  Using cached sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain==0.3.7)\n",
      "  Using cached aiohttp-3.12.14-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain==0.3.7)\n",
      "  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.7)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.7)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.3.7)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from langchain==0.3.7) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from langchain==0.3.7) (2.32.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from langchain==0.3.7) (9.1.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.7)\n",
      "  Downloading SQLAlchemy-2.0.35-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.7)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.7)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.7)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from langchain_google_genai==2.0.4) (0.8.5)\n",
      "Requirement already satisfied: click>=8.1.7 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from duckduckgo_search==6.3.4) (8.2.1)\n",
      "Collecting primp>=0.6.5 (from duckduckgo_search==6.3.4)\n",
      "  Downloading primp-0.15.0-cp38-abi3-win_amd64.whl.metadata (13 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph==0.2.48)\n",
      "  Using cached langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph==0.2.48)\n",
      "  Using cached langgraph_sdk-0.1.74-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.7)\n",
      "  Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: colorama in d:\\projects\\resumeats\\venv\\lib\\site-packages (from click>=8.1.7->duckduckgo_search==6.3.4) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (2.174.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (2.40.3)\n",
      "Requirement already satisfied: protobuf in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (5.29.5)\n",
      "Requirement already satisfied: tqdm in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (1.26.1)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain==0.3.7)\n",
      "  Downloading langchain_core-0.3.71-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.70-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.67-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Using cached langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
      "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.15->langchain==0.3.7)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.15->langchain==0.3.7)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.7)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Downloading orjson-3.11.1-cp311-cp311-win_amd64.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.2/43.2 kB ? eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph==0.2.48)\n",
      "  Using cached ormsgpack-1.10.0-cp311-cp311-win_amd64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.7) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.3.7) (2025.6.15)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain==0.3.7)\n",
      "  Using cached greenlet-3.2.3-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (4.9.1)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain==0.3.7)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.7)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (4.2.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (1.71.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\projects\\resumeats\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai==2.0.4) (0.6.1)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.7)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.0 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 0.9/1.0 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.0/2.4 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.5/2.4 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.0/2.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading langchain_google_genai-2.0.4-py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.8/41.8 kB ? eta 0:00:00\n",
      "Downloading duckduckgo_search-6.3.4-py3-none-any.whl (27 kB)\n",
      "Downloading langgraph-0.2.48-py3-none-any.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.8/124.8 kB 7.2 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.12.14-cp311-cp311-win_amd64.whl (452 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
      "   ---------------------------------------- 0.0/438.5 kB ? eta -:--:--\n",
      "   --------------------------------------  430.1/438.5 kB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 438.5/438.5 kB 9.1 MB/s eta 0:00:00\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Using cached langgraph_sdk-0.1.74-py3-none-any.whl (50 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Downloading primp-0.15.0-cp38-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.4/3.1 MB 12.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.9/3.1 MB 11.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.4/3.1 MB 10.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.8/3.1 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.2/3.1 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.6/3.1 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.0/3.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.1/3.1 MB 9.2 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.4/2.1 MB 11.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.1 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 8.9 MB/s eta 0:00:00\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached greenlet-3.2.3-cp311-cp311-win_amd64.whl (297 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Downloading orjson-3.11.1-cp311-cp311-win_amd64.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.4/131.4 kB 8.1 MB/s eta 0:00:00\n",
      "Using cached ormsgpack-1.10.0-cp311-cp311-win_amd64.whl (121 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, PyYAML, propcache, primp, packaging, ormsgpack, orjson, numpy, mypy-extensions, multidict, jsonpointer, httpx-sse, h11, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, marshmallow, jsonpatch, httpcore, duckduckgo_search, anyio, aiosignal, pydantic-settings, httpx, dataclasses-json, aiohttp, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langgraph, langchain_google_genai, langchain, langchain-community\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.1\n",
      "    Uninstalling numpy-2.3.1:\n",
      "      Successfully uninstalled numpy-2.3.1\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 anyio-4.9.0 dataclasses-json-0.6.7 duckduckgo_search-6.3.4 frozenlist-1.7.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.7 langchain-community-0.3.7 langchain-core-0.3.63 langchain-text-splitters-0.3.8 langchain_google_genai-2.0.4 langgraph-0.2.48 langgraph-checkpoint-2.1.1 langgraph-sdk-0.1.74 langsmith-0.1.147 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 numpy-1.26.4 orjson-3.11.1 ormsgpack-1.10.0 packaging-24.2 primp-0.15.0 propcache-0.3.2 pydantic-settings-2.10.1 requests-toolbelt-1.0.0 sniffio-1.3.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain==0.3.7 langchain-community==0.3.7 langchain_google_genai==2.0.4 duckduckgo_search==6.3.4 langgraph==0.2.48 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fd4d2-e9f2-420b-9ae3-813d6b99142d",
   "metadata": {},
   "source": [
    "### Here we will import necessary packages:\n",
    "`langgraph`, `langchain_core`, `langchain_google_genai` - These are important packages for our project.\n",
    "\n",
    "This code imports necessary libraries to create and interact with a generative AI model from Google. It loads environment variables to securely set up an API key, then configures the model `gemini-1.5-flash` with specific parameters like verbosity (for detailed logs) and temperature (for response creativity). The AI model is instantiated with the API key to enable its use in generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553b016a-35eb-435d-bb44-7fc70901f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END, START #Importing StateGraph, END, and START from langgraph.graph to define and manage state transitions within a conversational or generative AI workflow.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from IPython.display import display, Image, Markdown\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod # to visualize the graph of langgraph node and edges\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file to access sensitive information\n",
    "load_dotenv()\n",
    "\n",
    "# Set the Gemini API key for authentication with Google Generative AI services\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Instantiate a chat model using Google's Gemini-1.5-flash with specified configurations\n",
    "# - verbose=True enables detailed output logs for debugging\n",
    "# - temperature=0.5 controls the creativity level in responses (lower values make responses more deterministic)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
    "                             verbose=True,\n",
    "                             temperature=0.5,\n",
    "                             google_api_key=os.getenv(\"GEMINI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc5e74-70f8-4bda-93e0-a734c223c14b",
   "metadata": {},
   "source": [
    "### Defining a State class using TypedDict to specify the structure of state data in the workflow.\n",
    "- `query`: a string representing the user's input or question.\n",
    "- `category`: a string indicating the category or type of the query.\n",
    "- `response`: a string holding the AI model's generated response to the query.\n",
    "This TypedDict ensures each state has a consistent data format for easier management and readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f28752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    query: str\n",
    "    category: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd99d3-4a97-44dd-bb4f-5537f9099f0a",
   "metadata": {},
   "source": [
    "### First we are defining utilities we will require further\n",
    "<a href=\"https://python.langchain.com/docs/how_to/trim_messages/\"> ðŸ‘‰ trim_messages <a>\n",
    "\n",
    "1. **`trim_conversation` Function**: This function limits the conversation history to the latest messages (up to 10), ensuring only recent and relevant messages are retained in the promp\n",
    "  \n",
    "2. **`save_file` Function**: Saves data into a uniquely timestamped Markdown file in the `Agent_output` folder, creating the folder if it doesn't exst.\n",
    "\n",
    "3. **`show_md_file` Function**: Reads and displays the content of a Markdown file within the notebook, rendering it in Markdown form readabilityblity.\n",
    "lity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e70488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing message types and utilities from langchain_core:\n",
    "# AIMessage, HumanMessage, SystemMessage: Define different types of messages in a conversation.\n",
    "# trim_messages: Utility to manage and limit the number of messages in a conversation history.\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, trim_messages\n",
    "\n",
    "def trim_conversation(prompt):\n",
    "    \"\"\"Trims conversation history to retain only the latest messages within the limit.\"\"\"\n",
    "    max_messages = 10  # Limit the conversation history to the latest 10 messages\n",
    "    return trim_messages(\n",
    "        prompt,\n",
    "        max_tokens=max_messages,  # Specifies the maximum number of messages allowed\n",
    "        strategy=\"last\",  # Trimming strategy to keep the last messages\n",
    "        token_counter=len,  # Counts tokens/messages using the length of the list\n",
    "        start_on=\"human\",  # Start trimming when reaching the first human message\n",
    "        include_system=True,  # Include system messages in the trimmed history\n",
    "        allow_partial=False,  # Ensures only whole messages are included\n",
    "    )\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_file(data, filename):\n",
    "    \"\"\"Saves data to a markdown file with a timestamped filename.\"\"\"\n",
    "    folder_name = \"Agent_output\"  # Folder to store output files\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Creates the folder if it doesn't exist\n",
    "    \n",
    "    # Generate a timestamped filename for uniqueness\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")  # Format: YYYYMMDDHHMMSS\n",
    "    filename = f\"{filename}_{timestamp}.md\"\n",
    "    \n",
    "    # Define the full file path\n",
    "    file_path = os.path.join(folder_name, filename)\n",
    "    \n",
    "    # Save the data to the file in the specified path\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(data)\n",
    "        print(f\"File '{file_path}' created successfully.\")\n",
    "    \n",
    "    # Return the full path of the saved file\n",
    "    return file_path\n",
    "\n",
    "def show_md_file(file_path):\n",
    "    \"\"\"Displays the content of a markdown file as Markdown in the notebook.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Render the content in Markdown format within the notebook\n",
    "    display(Markdown(content))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72afb0e-e9e0-435a-8017-b59c79dbc281",
   "metadata": {},
   "source": [
    "#### Now We will create class which will be Responsible for Learning(Tutorial and Q&A sessions)\n",
    "- Checkout here:\n",
    "<a href=\"https://python.langchain.com/v0.1/docs/modules/agents/agent_types/tool_calling/\">ðŸ‘‰ create_tool_calling_agent <a>\n",
    "<a href=\"https://python.langchain.com/docs/how_to/agent_executor/\">ðŸ‘‰ AgentExecutor <a>\n",
    "<a href=\"https://python.langchain.com/docs/integrations/tools/ddg/\">ðŸ‘‰ DuckDuckGoSearchResults <a>\n",
    "\n",
    "1. **Imports**: \n",
    "   - `ChatPromptTemplate` and `MessagesPlaceholder` from `langchain_core.prompts` help structure prompts.\n",
    "   - `DuckDuckGoSearchResults` from `langchain_community.tools` provides web search capability.\n",
    "   - `create_tool_calling_agent` and `AgentExecutor` manage agent creation and execution.\n",
    "\n",
    "2. **`LearningResourceAgent` Class**:\n",
    "   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and tools (like DuckDuckGo search).\n",
    "   - **`TutorialAgent` Method**: Runs a search-based tutorial by invoking the model and saving the output as a timestamped Markdown file for review.\n",
    "   - **`QueryBot` Method**: Conducts a Q&A loop with the user. The conversation is trimmed as it grows, and responses are generated based on updated inputs, with the user able to type 'exit' to end the session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068e34b5-596b-4eb3-b1ae-89281b216284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.tools import DuckDuckGoSearchResults #searching tools\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "class LearningResourceAgent:\n",
    "    def __init__(self, prompt):\n",
    "        # Initialize the chat model, prompt template, and search tools\n",
    "        self.model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "        self.prompt = prompt\n",
    "        self.tools = [DuckDuckGoSearchResults()]\n",
    "\n",
    "    def TutorialAgent(self, user_input):\n",
    "        # Set up an agent with tool access and execute a tutorial-style response\n",
    "        agent = create_tool_calling_agent(self.model, self.tools, self.prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=self.tools, verbose=True)\n",
    "        response = agent_executor.invoke({\"input\": user_input})\n",
    "        \n",
    "        # Save and display the response as a markdown file\n",
    "        path = save_file(str(response.get('output')).replace(\"```markdown\", \"\").strip(), 'Tutorial')\n",
    "        print(f\"Tutorial saved to {path}\")\n",
    "        return path\n",
    "\n",
    "    def QueryBot(self, user_input):\n",
    "        # Initiates a Q&A loop for continuous interaction with the user\n",
    "        print(\"\\nStarting the Q&A session. Type 'exit' to end the session.\\n\")\n",
    "        record_QA_session = []\n",
    "        record_QA_session.append('User Query: %s \\n' % user_input)\n",
    "        self.prompt.append(HumanMessage(content=user_input))\n",
    "        while True:\n",
    "            # Trim conversation history to maintain prompt size\n",
    "            self.prompt = trim_conversation(self.prompt)\n",
    "            \n",
    "            # Generate a response from the AI model and update conversation history\n",
    "            response = self.model.invoke(self.prompt)\n",
    "            record_QA_session.append('\\nExpert Response: %s \\n' % response.content)\n",
    "            \n",
    "            self.prompt.append(AIMessage(content=response.content))\n",
    "            \n",
    "            # Display the AI's response and prompt for user input\n",
    "            print('*' * 50 + 'AGENT' + '*' * 50)\n",
    "            print(\"\\nEXPERT AGENT RESPONSE:\", response.content)\n",
    "            \n",
    "            print('*' * 50 + 'USER' + '*' * 50)\n",
    "            user_input = input(\"\\nYOUR QUERY: \")\n",
    "            record_QA_session.append('\\nUser Query: %s \\n' % response.content)\n",
    "            self.prompt.append(HumanMessage(content=user_input))\n",
    "            \n",
    "            # Exit the Q&A loop if the user types 'exit'\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Ending the chat session.\")\n",
    "                path = save_file(''.join(record_QA_session),'Q&A_Doubt_Session')\n",
    "                print(f\"Q&A Session saved to {path}\")\n",
    "                return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580c6d7-3872-4d86-bbff-ddfc2159f382",
   "metadata": {},
   "source": [
    "### Here we are creating Class for Interview handling(Interview Question Prep and MockInterview)\n",
    "\n",
    "1. **`InterviewAgent` Class**:\n",
    "   - **`__init__` Method**: Initializes the model (`gemini-1.5-flash`), prompt, tools (such as DuckDuckGo search), and creates an agent executor with error handling enabled.\n",
    "\n",
    "2. **`Interview_questions` Method**:\n",
    "   - Runs a loop for handling interview questions from the user, generating responses using the agent executor. \n",
    "   - Responses are stored in `questions_bank` for later reference. The conversation ends when the user types \"exit,\" and the chat history is saved as a Markdown file.\n",
    "\n",
    "3. **`Mock_Interview` Method**:\n",
    "   - Simulates a mock interview by initiating a conversation loop. Responses from the model are displayed as \"Interviewer\" messages, and user inputs as \"Candidate\" messages.\n",
    "   - The conversation is trimmed as it grows to maintain prompt size. The interview session ends when the user types \"exit,\" returning a record of the entire interview.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4f3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewAgent:\n",
    "    def __init__(self, prompt):\n",
    "        # Initialize the chat model, prompt template, and search tool for use in the agent\n",
    "        self.model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "        self.prompt = prompt\n",
    "        self.tools = [DuckDuckGoSearchResults()]  # Web search tool for retrieving additional information\n",
    "\n",
    "    def Interview_questions(self, user_input):\n",
    "        # Holds the conversation history and cumulative questions and answers\n",
    "        chat_history = []\n",
    "        questions_bank = ''\n",
    "        # Create an agent executor with tool access and enable verbose output and error handling\n",
    "        self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "        while True:\n",
    "            print(\"\\nStarting the Interview question preparation. Type 'exit' to end the session.\\n\")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Ending the conversation. Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            # Generate a response to the user input and add it to questions_bank\n",
    "            response = self.agent_executor.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "            questions_bank += str(response.get('output')).replace(\"```markdown\", \"\").strip() + \"\\n\"\n",
    "            \n",
    "            # Update chat history with user input and AI response, limiting history to the last 10 messages\n",
    "            chat_history.extend([HumanMessage(content=user_input), response[\"output\"]])\n",
    "            if len(chat_history) > 10:\n",
    "                chat_history = chat_history[-10:]  # Keep only the last 10 messages\n",
    "            \n",
    "            # Get the next input from the user to continue the conversation\n",
    "            user_input = input(\"You: \")\n",
    "        \n",
    "        # Save the entire question-response history to a markdown file and display it\n",
    "        path = save_file(questions_bank, 'Interview_questions')\n",
    "        print(f\"Interviews question saved to {path}\")\n",
    "        return path\n",
    "\n",
    "    def Mock_Interview(self):\n",
    "        # Start a simulated mock interview session\n",
    "        print(\"\\nStarting the mock interview. Type 'exit' to end the session.\\n\")\n",
    "        \n",
    "        # Initialize with a starting message and store interview records\n",
    "        initial_message = 'I am ready for the interview.\\n'\n",
    "        interview_record = []\n",
    "        interview_record.append('Candidate: %s \\n' % initial_message)\n",
    "        self.prompt.append(HumanMessage(content=initial_message))\n",
    "        \n",
    "        while True:\n",
    "            # Trim conversation history if necessary to maintain prompt size\n",
    "            self.prompt = trim_conversation(self.prompt)\n",
    "            \n",
    "            # Generate a response using the chat model\n",
    "            response = self.model.invoke(self.prompt)\n",
    "            \n",
    "            # Add AI response to the conversation history\n",
    "            self.prompt.append(AIMessage(content=response.content))\n",
    "            \n",
    "            # Output the AI's response as the \"Interviewer\"\n",
    "            print(\"\\nInterviewer:\", response.content)\n",
    "            interview_record.append('\\nInterviewer: %s \\n' % response.content)\n",
    "            \n",
    "            # Get the user's response as \"Candidate\" input\n",
    "            user_input = input(\"\\nCandidate: \")\n",
    "            interview_record.append('\\nCandidate: %s \\n' % user_input)\n",
    "            \n",
    "            # Add user input to the conversation history\n",
    "            self.prompt.append(HumanMessage(content=user_input))\n",
    "            \n",
    "            # End the interview if the user types \"exit\"\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Ending the interview session.\")\n",
    "                path = save_file(''.join(interview_record),'Mock_Interview')\n",
    "                print(f\"Mock Interview saved to {path}\")\n",
    "                return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d1e00-3b9b-44b0-a740-0f6194dec1cb",
   "metadata": {},
   "source": [
    "### Now we will create class for Resume Making which will handle creating resume by chating with user\n",
    "\n",
    "1. **`ResumeMaker` Class**:\n",
    "   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and tools (like DuckDuckGo search). Sets up an agent executor with tool access, verbose output, and error handling for generating resume content.\n",
    "\n",
    "2. **`Create_Resume` Method**:\n",
    "   - Engages in a conversational loop to gather user input and generate resume content based on responses from the agent.\n",
    "   - The conversation history (`chat_history`) retains only the latest 10 messages to manage context size.\n",
    "   - The conversation loop ends when the user types \"exit,\" at which point the final output is saved as a timestamped Markdown file titled \"Resume,\" and the file path is displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e520d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeMaker:\n",
    "    def __init__(self, prompt):\n",
    "        # Initialize the chat model, prompt template, and search tool for resume creation\n",
    "        self.model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "        self.prompt = prompt\n",
    "        self.tools = [DuckDuckGoSearchResults()]  # Search tool to gather additional information if needed\n",
    "        # Create an agent executor with tool access, enabling verbose output and error handling\n",
    "        self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)\n",
    "        self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "    def Create_Resume(self, user_input):\n",
    "        # Maintain chat history for the resume creation conversation\n",
    "        chat_history = []\n",
    "        while True:\n",
    "            print(\"\\nStarting the Resume create session. Type 'exit' to end the session.\\n\")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Ending the conversation. Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            # Generate a response to user input using the agent and add it to the chat history\n",
    "            response = self.agent_executor.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "            chat_history.extend([HumanMessage(content=user_input), response[\"output\"]])\n",
    "            \n",
    "            # Limit the chat history to the last 10 messages\n",
    "            if len(chat_history) > 10:\n",
    "                chat_history = chat_history[-10:]\n",
    "            \n",
    "            # Prompt for the next user input to continue the resume creation conversation\n",
    "            user_input = input(\"You: \")\n",
    "        \n",
    "        # Save the final output as a markdown file and return the file path\n",
    "        path = save_file(str(response.get('output')).replace(\"```markdown\", \"\").strip(), 'Resume')\n",
    "        print(f\"Resume saved to {path}\")\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3f2764-2e61-46c0-ac66-05b278d9ae0d",
   "metadata": {},
   "source": [
    "### Code Explanation\n",
    "\n",
    "1. **`JobSearch` Class**:\n",
    "   - **`__init__` Method**: Initializes the chat model (`gemini-1.5-pro`), prompt, and search tools for job search assistance. Sets up an agent executor to handle conversation flow with verbose output and error handling.\n",
    "\n",
    "2. **`find_jobs` Method**:\n",
    "   - Conducts a conversational loop to assist users with job search queries, using the agent's responses based on user input.\n",
    "   - Retains only the latest 10 messages in `chat_history` to manage the prompt size effectively.\n",
    "   - The loop ends when the user types \"exit,\" after which the final conversation output is saved to a Markdown file titled \"Resume,\" and the file path is displayed to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e402606",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobSearch:\n",
    "    def __init__(self, prompt):\n",
    "        # Initialize the chat model, prompt template, and search tool for job search assistance\n",
    "        self.model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "        self.prompt = prompt\n",
    "        self.tools = DuckDuckGoSearchResults()  # Search tool to find job listings or related information\n",
    "        # Create an agent executor with tool access, enabling verbose output and error handling\n",
    "        # self.agent = create_tool_calling_agent(self.model, self.tools, self.prompt)\n",
    "        # self.agent_executor = AgentExecutor(agent=self.agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "    def find_jobs(self, user_input):\n",
    "        results = self.tools.invoke(user_input)\n",
    "        chain = self.prompt | self.model  \n",
    "        jobs = chain.invoke({\"result\": results}).content\n",
    "        \n",
    "        path = save_file(str(jobs).replace(\"```markdown\", \"\").strip(), 'Job_search')\n",
    "        print(f\"Jobs saved to {path}\")\n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e328d5c6-e9fb-4f19-a8de-1e740bff2a40",
   "metadata": {},
   "source": [
    "### Now we are creating function which will help to categorize our user Input\n",
    "- We are using <a href=\"https://python.langchain.com/docs/how_to/few_shot_examples/\">ðŸ‘‰ Few Shot prompting </a>(Checkout here) to make our LLM understand the categories.\n",
    "1. **`categorize` Function**:\n",
    "   - Categorizes a user query into four main areas: Learning Generative AI, Resume Making, Interview Preparation, or Job Search.\n",
    "   - Uses a template prompt with examples to guide the AI in choosing the correct category and returns the category number.\n",
    "\n",
    "2. **`handle_learning_resource` Function**:\n",
    "   - Determines if a user query about generative AI is related to creating tutorials or asking general questions.\n",
    "   - Uses a prompt to specify these categories and returns \"Tutorial\" or \"Question\" based on the AI's categorization.\n",
    "\n",
    "3. **`handle_interview_preparation` Function**:\n",
    "   - Identifies if a user query in the interview category is about a mock interview or general interview questions.\n",
    "   - Uses examples to instruct the AI on the difference, returning either \"Mock\" or \"Question\" to guide further interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d053e39b-f986-4c21-83a3-6b2ea9acbe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(state: State) -> State:\n",
    "    \"\"\"Categorizes the user query into one of four main categories: Learn Generative AI Technology, Resume Making, Interview Preparation, or Job Search.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following customer query into one of these categories:\\n\"\n",
    "        \"1: Learn Generative AI Technology\\n\"\n",
    "        \"2: Resume Making\\n\"\n",
    "        \"3: Interview Preparation\\n\"\n",
    "        \"4: Job Search\\n\"\n",
    "        \"Give the number only as an output.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"1. Query: 'What are the basics of generative AI, and how can I start learning it?' -> 1\\n\"\n",
    "        \"2. Query: 'Can you help me improve my resume for a tech position?' -> 2\\n\"\n",
    "        \"3. Query: 'What are some common questions asked in AI interviews?' -> 3\\n\"\n",
    "        \"4. Query: 'Are there any job openings for AI engineers?' -> 4\\n\\n\"\n",
    "        \"Now, categorize the following customer query:\\n\"\n",
    "        \"Query: {query}\"\n",
    "    )\n",
    "\n",
    "    # Creates a categorization chain and invokes it with the user's query to get the category\n",
    "    chain = prompt | llm \n",
    "    print('Categorizing the customer query...')\n",
    "    category = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": category}\n",
    "\n",
    "def handle_learning_resource(state: State) -> State:\n",
    "    \"\"\"Determines if the query is related to Tutorial creation or general Questions on generative AI topics.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following user query into one of these categories:\\n\\n\"\n",
    "        \"Categories:\\n\"\n",
    "        \"- Tutorial: For queries related to creating tutorials, blogs, or documentation on generative AI.\\n\"\n",
    "        \"- Question: For general queries asking about generative AI topics.\\n\"\n",
    "        \"- Default to Question if the query doesn't fit either of these categories.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"1. User query: 'How to create a blog on prompt engineering for generative AI?' -> Category: Tutorial\\n\"\n",
    "        \"2. User query: 'Can you provide a step-by-step guide on fine-tuning a generative model?' -> Category: Tutorial\\n\"\n",
    "        \"3. User query: 'Provide me the documentation for Langchain?' -> Category: Tutorial\\n\"\n",
    "        \"4. User query: 'What are the main applications of generative AI?' -> Category: Question\\n\"\n",
    "        \"5. User query: 'Is there any generative AI course available?' -> Category: Question\\n\\n\"\n",
    "        \"Now, categorize the following user query:\\n\"\n",
    "        \"The user query is: {query}\\n\"\n",
    "    )\n",
    "\n",
    "    # Creates a further categorization chain to decide between Tutorial or Question\n",
    "    chain = prompt | llm \n",
    "    print('Categorizing the customer query further...')\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": response}\n",
    "\n",
    "def handle_interview_preparation(state: State) -> State:\n",
    "    \"\"\"Determines if the query is related to Mock Interviews or general Interview Questions.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Categorize the following user query into one of these categories:\\n\\n\"\n",
    "        \"Categories:\\n\"\n",
    "        \"- Mock: For requests related to mock interviews.\\n\"\n",
    "        \"- Question: For general queries asking about interview topics or preparation.\\n\"\n",
    "        \"- Default to Question if the query doesn't fit either of these categories.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"1. User query: 'Can you conduct a mock interview with me for a Gen AI role?' -> Category: Mock\\n\"\n",
    "        \"2. User query: 'What topics should I prepare for an AI Engineer interview?' -> Category: Question\\n\"\n",
    "        \"3. User query: 'I need to practice interview focused on Gen AI.' -> Category: Mock\\n\"\n",
    "        \"4. User query: 'Can you list important coding topics for AI tech interviews?' -> Category: Question\\n\\n\"\n",
    "        \"Now, categorize the following user query:\\n\"\n",
    "        \"The user query is: {query}\\n\"\n",
    "    )\n",
    "\n",
    "    # Creates a further categorization chain to decide between Mock or Question\n",
    "    chain = prompt | llm \n",
    "    print('Categorizing the customer query further...')\n",
    "    response = chain.invoke({\"query\": state[\"query\"]}).content\n",
    "    return {\"category\": response}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca2e35-d37b-45a7-b228-6c04d51f4231",
   "metadata": {},
   "source": [
    "### Now we will create function for job search and Resume making\n",
    "\n",
    "1. **`job_search` Function**:\n",
    "   - Sets up a job search agent to find Generative AI job listings based on user input, gathering details like company name, job title, and links.\n",
    "   - Generates a Markdown (.md) file with results, displayed to the user.\n",
    "\n",
    "2. **`handle_resume_making` Function**:\n",
    "   - Creates a customized resume for AI-focused roles by gathering user details (skills, experience, projects) in a structured format.\n",
    "   - Produces a Markdown (.md) resume template tailored to the Generative AI jobcandidate's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c60b01-a5be-4f71-a356-cb5b6fbaad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_search(state: State) -> State:\n",
    "    \"\"\"Provide a job search response based on user query requirements.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template('''Your task is to refactor and make .md file for the this content which includes\n",
    "    the jobs available in the market. Refactor such that user can refer easily. Content: {result}''')\n",
    "    jobSearch = JobSearch(prompt)\n",
    "    state[\"query\"] = input('Please make sure to mention Job location you want,Job roles\\n')\n",
    "    path = jobSearch.find_jobs(state[\"query\"])\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}\n",
    "\n",
    "def handle_resume_making(state: State) -> State:\n",
    "    \"\"\"Generate a customized resume based on user details for a tech role in AI and Generative AI.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", '''You are a skilled resume expert with extensive experience in crafting resumes tailored for tech roles, especially in AI and Generative AI. \n",
    "        Your task is to create a resume template for an AI Engineer specializing in Generative AI, incorporating trending keywords and technologies in the current job market. \n",
    "        Feel free to ask users for any necessary details such as skills, experience, or projects to complete the resume. \n",
    "        Try to ask details step by step and try to ask all details within 4 to 5 steps.\n",
    "        Ensure the final resume is in .md format.'''),\n",
    "       MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "    resumeMaker = ResumeMaker(prompt)\n",
    "    path = resumeMaker.Create_Resume(state[\"query\"])\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df818050-866e-4c56-aebd-7588e6bddd88",
   "metadata": {},
   "source": [
    "### Next we will create a function for Q&A query bot and Tutorial maker\n",
    "\n",
    "3. **`ask_query_bot` Function**:\n",
    "   - Engages in a conversational Q&A session, providing detailed answers to user queries related to Generative AI.\n",
    "   - Uses back-and-forth interaction to ensure clarity and completeness in responses.\n",
    "\n",
    "4. **`tutorial_agent` Function**:\n",
    "   - Generates comprehensive tutorial blogs on Generative AI topics with explanations, example code, and resources for further learning.\n",
    "   - Saves the tutorial in Markdown (.md) format, designed for clarity and learning support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0ed58d-b28d-457f-8111-6d1138803e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_query_bot(state: State) -> State:\n",
    "    \"\"\"Provide detailed answers to user queries related to Generative AI.\"\"\"\n",
    "    system_message = '''You are an expert Generative AI Engineer with extensive experience in training and guiding others in AI engineering. \n",
    "    You have a strong track record of solving complex problems and addressing various challenges in AI. \n",
    "    Your role is to assist users by providing insightful solutions and expert advice on their queries.\n",
    "    Engage in a back-and-forth chat session to address user queries.'''\n",
    "    prompt = [SystemMessage(content=system_message)]\n",
    "\n",
    "    learning_agent = LearningResourceAgent(prompt)\n",
    "\n",
    "    path = learning_agent.QueryBot(state[\"query\"])\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}\n",
    "\n",
    "def tutorial_agent(state: State) -> State:\n",
    "    \"\"\"Generate a tutorial blog for Generative AI based on user requirements.\"\"\"\n",
    "    system_message = '''You are a knowledgeable assistant specializing as a Senior Generative AI Developer with extensive experience in both development and tutoring. \n",
    "         Additionally, you are an experienced blogger who creates tutorials focused on Generative AI.\n",
    "         Your task is to develop high-quality tutorials blogs in .md file with Coding example based on the user's requirements. \n",
    "         Ensure tutorial includes clear explanations, well-structured python code, comments, and fully functional code examples.\n",
    "         Provide resource reference links at the end of each tutorial for further learning.'''\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system_message),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),])\n",
    "    #agent_scratchpad is a function that formats the intermediate steps of the agent's actions and observations into a string. \n",
    "    #This function is used to keep track of the agent's thoughts or actions during the execution of the program. But its not necessary, we can do without this so we will not include it only define it.\n",
    "    learning_agent = LearningResourceAgent(prompt)\n",
    "    path = learning_agent.TutorialAgent(state[\"query\"])\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2627e11-0dce-4374-8c47-3541125981a4",
   "metadata": {},
   "source": [
    "### Finally we will create function Interview Question prep and Mock interview\n",
    "\n",
    "5. **`interview_topics_quesions` Function**:\n",
    "   - Provides a list of interview questions tailored to Generative AI roles, along with references where possible.\n",
    "   - Outputs a Markdown (.md) document with curated questions based on user requirements.\n",
    "\n",
    "6. **`mock_interview` Function**:\n",
    "   - Conducts a simulated Generative AI job interview, interacting with the user in real-time.\n",
    "   - Provides a post-interview evaluation, summarizing the candidate's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbef12ea-9dde-4408-a7d6-8e2a3e10e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_topics_questions(state: State) -> State:\n",
    "    \"\"\"Provide a curated list of interview questions related to Generative AI based on user input.\"\"\"\n",
    "    system_message = '''You are a good researcher in finding interview questions for Generative AI topics and jobs.\n",
    "                     Your task is to provide a list of interview questions for Generative AI topics and job based on user requirements.\n",
    "                     Provide top questions with references and links if possible. You may ask for clarification if needed.\n",
    "                     Generate a .md document containing the questions.'''\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "                        (\"system\", system_message),\n",
    "                        MessagesPlaceholder(\"chat_history\"),\n",
    "                        (\"human\", \"{input}\"),\n",
    "                        (\"placeholder\", \"{agent_scratchpad}\"),])\n",
    "    interview_agent = InterviewAgent(prompt)\n",
    "    path = interview_agent.Interview_questions(state[\"query\"])\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}\n",
    "\n",
    "def mock_interview(state: State) -> State:\n",
    "    \"\"\"Conduct a mock interview for a Generative AI position, including evaluation at the end.\"\"\"\n",
    "    system_message = '''You are a Generative AI Interviewer. You have conducted numerous interviews for Generative AI roles.\n",
    "         Your task is to conduct a mock interview for a Generative AI position, engaging in a back-and-forth interview session.\n",
    "         The conversation should not exceed more than 15 to 20 minutes.\n",
    "         At the end of the interview, provide an evaluation for the candidate.'''\n",
    "    prompt = [SystemMessage(content=system_message)]\n",
    "    interview_agent = InterviewAgent(prompt)\n",
    "    path = interview_agent.Mock_Interview()\n",
    "    show_md_file(path)\n",
    "    return {\"response\": path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12e827-16f9-46a5-9a81-ba4edd44ccd7",
   "metadata": {},
   "source": [
    "### Here, We are creating routing function which will be responsible for conditional edge to give direction after categorization.\n",
    "- Checkout Here<a href=\"https://langchain-ai.github.io/langgraph/#:~:text=Conditional%20edge%20means%20that%20the,the%20agent%20(LLM)%20decides.\">ðŸ‘‰ Conditional Edge</a>\n",
    "1. **`route_query` Function**:\n",
    "   - Routes the main query based on the assigned category number, directing it to the appropriate handler: Learning Resource, Resume Making, Interview Preparation, or Job Search.\n",
    "   - If the query does not match any predefined categories, prompts the user to ask a more relevant question.\n",
    "\n",
    "2. **`route_interview` Function**:\n",
    "   - Routes interview-related queries to specific handlers based on the query's sub-category (either Mock Interview or Interview Topics).\n",
    "   - If the category is unclear, defaults to \"mock_interview.\"\n",
    "\n",
    "3. **`route_learning` Function**:\n",
    "   - Routes learning-related queries, directing them to either a general question bot or a tutorial creation agent.\n",
    "   - Returns `False` if the query does not clearly fit either sub-category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f31dd1-9edc-447c-9cb3-cb4f71c73a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state: State):\n",
    "    \"\"\"Route the query based on its category to the appropriate handler.\"\"\"\n",
    "    if '1' in state[\"category\"]:\n",
    "        print('Category: handle_learning_resource')\n",
    "        return \"handle_learning_resource\"  # Directs queries about learning generative AI to the learning resource handler\n",
    "    elif '2' in state[\"category\"]:\n",
    "        print('Category: handle_resume_making')\n",
    "        return \"handle_resume_making\"  # Directs queries about resume making to the resume handler\n",
    "    elif '3' in state[\"category\"]:\n",
    "        print('Category: handle_interview_preparation')\n",
    "        return \"handle_interview_preparation\"  # Directs queries about interview preparation to the interview handler\n",
    "    elif '4' in state[\"category\"]:\n",
    "        print('Category: job_search')\n",
    "        return \"job_search\"  # Directs job search queries to the job search handler\n",
    "    else:\n",
    "        print(\"Please ask your question based on my description.\")\n",
    "        return False  # Returns False if the category does not match any predefined options\n",
    "\n",
    "def route_interview(state: State) -> str:\n",
    "    \"\"\"Route the query to the appropriate interview-related handler.\"\"\"\n",
    "    if 'Question'.lower() in state[\"category\"].lower():\n",
    "        print('Category: interview_topics_questions')\n",
    "        return \"interview_topics_questions\"  # Directs to the handler for interview topic questions\n",
    "    elif 'Mock'.lower() in state[\"category\"].lower():\n",
    "        print('Category: mock_interview')\n",
    "        return \"mock_interview\"  # Directs to the mock interview handler\n",
    "    else:\n",
    "        print('Category: mock_interview')\n",
    "        return \"mock_interview\"  # Defaults to mock interview if category does not clearly match\n",
    "\n",
    "def route_learning(state: State):\n",
    "    \"\"\"Route the query based on the learning path category.\"\"\"\n",
    "    if 'Question'.lower() in state[\"category\"].lower():\n",
    "        print('Category: ask_query_bot')\n",
    "        return \"ask_query_bot\"  # Directs queries to the general question bot\n",
    "    elif 'Tutorial'.lower() in state[\"category\"].lower():\n",
    "        print('Category: tutorial_agent')\n",
    "        return \"tutorial_agent\"  # Directs queries to the tutorial creation agent\n",
    "    else:\n",
    "        print(\"Please ask your question based on my interview description.\")\n",
    "        return False  # Returns False if no clear category match is found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d30406-4f79-4eaf-8d86-cb98c20d764d",
   "metadata": {},
   "source": [
    "### Now all set lets create workflow graphs adding edges and nodes.\n",
    "\n",
    "1. **Workflow Creation**:\n",
    "   - Initializes a `StateGraph` to define the workflow for query handling, with each node representing a different query handler.\n",
    "\n",
    "2. **Nodes and Edges**:\n",
    "   - Adds nodes for each query category and handling function: `categorize`, `handle_learning_resource`, `handle_resume_making`, `handle_interview_preparation`, and `job_search`.\n",
    "   - Adds edges to connect nodes conditionally based on the category (e.g., `route_query` routes from \"categorize\" to the appropriate handler).\n",
    "   - Conditional edges further route within specific categories, such as learning resources (`route_learning`) and interview preparation (`route_interview`).\n",
    "\n",
    "3. **Workflow Endpoints**:\n",
    "   - Defines nodes where the workflow terminates (e.g., `handle_resume_making`, `mock_interview`, and `job_search`), connecting them to `END`.\n",
    "\n",
    "4. **Compilation**:\n",
    "   - Sets `categorize` as the entry point and compiles the workflow into an executable application, `app`, for handling user queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e932ca15-983a-4bff-8ed9-51e62323f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the workflow graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes for each state in the workflow\n",
    "workflow.add_node(\"categorize\", categorize)  # Initial categorization node\n",
    "workflow.add_node(\"handle_learning_resource\", handle_learning_resource)  # Handles learning-related queries\n",
    "workflow.add_node(\"handle_resume_making\", handle_resume_making)  # Handles resume-making queries\n",
    "workflow.add_node(\"handle_interview_preparation\", handle_interview_preparation)  # Handles interview prep queries\n",
    "workflow.add_node(\"job_search\", job_search)  # Handles job search queries\n",
    "workflow.add_node(\"mock_interview\", mock_interview)  # Handles mock interview sessions\n",
    "workflow.add_node(\"interview_topics_questions\", interview_topics_questions)  # Handles interview topic questions\n",
    "workflow.add_node(\"tutorial_agent\", tutorial_agent)  # Tutorial agent for generative AI learning resources\n",
    "workflow.add_node(\"ask_query_bot\", ask_query_bot)  # General query bot for learning resources\n",
    "\n",
    "# Define the starting edge to the categorization node\n",
    "workflow.add_edge(START, \"categorize\")\n",
    "\n",
    "# Add conditional edges based on category routing function\n",
    "workflow.add_conditional_edges(\n",
    "    \"categorize\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"handle_learning_resource\": \"handle_learning_resource\",\n",
    "        \"handle_resume_making\": \"handle_resume_making\",\n",
    "        \"handle_interview_preparation\": \"handle_interview_preparation\",\n",
    "        \"job_search\": \"job_search\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conditional edges for further routing in interview preparation\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_interview_preparation\",\n",
    "    route_interview,\n",
    "    {\n",
    "        \"mock_interview\": \"mock_interview\",\n",
    "        \"interview_topics_questions\": \"interview_topics_questions\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add conditional edges for further routing in learning resources\n",
    "workflow.add_conditional_edges(\n",
    "    \"handle_learning_resource\",\n",
    "    route_learning,\n",
    "    {\n",
    "        \"tutorial_agent\": \"tutorial_agent\",\n",
    "        \"ask_query_bot\": \"ask_query_bot\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define edges that lead to the end of the workflow\n",
    "workflow.add_edge(\"handle_resume_making\", END)\n",
    "workflow.add_edge(\"job_search\", END)\n",
    "workflow.add_edge(\"interview_topics_questions\", END)\n",
    "workflow.add_edge(\"mock_interview\", END)\n",
    "workflow.add_edge(\"ask_query_bot\", END)\n",
    "workflow.add_edge(\"tutorial_agent\", END)\n",
    "\n",
    "# Set the initial entry point to start the workflow at the categorize node\n",
    "workflow.set_entry_point(\"categorize\")\n",
    "\n",
    "# Compile the workflow graph into an application\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc25655d-72d8-44d4-b049-983b168c2429",
   "metadata": {},
   "source": [
    "### Lets Visualize our graph\n",
    "\n",
    "- **Displaying Workflow Graph**:\n",
    "  - Generates a visual representation of the `app` workflow graph using Mermaid, which is then displayed as a PNG image.\n",
    "  - The `MermaidDrawMethod.API` method is used to create the PNG, ensuring a clear, structured view of the workflow nodes and their connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab9b40e-5ea0-4147-a8fc-c30d7a018dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the workflow graph as a PNG image using Mermaid\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,  # Uses Mermaid's API to generate the PNG image of the workflow graph\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71869f0f-9339-4ef9-8873-5543701a27c3",
   "metadata": {},
   "source": [
    "### Final function to Processes a user query using the LangGraph workflow and returns a dictionary containing the query's category and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40306bbb-b2d7-4964-9b4e-0c2c0daddbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_user_query(query: str) -> Dict[str, str]:\n",
    "    \"\"\"Process a user query through the LangGraph workflow.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's query\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the query's category and response\n",
    "    \"\"\"\n",
    "    results = app.invoke({\"query\": query})\n",
    "    return {\n",
    "        \"category\": results[\"category\"],\n",
    "        \"response\": results[\"response\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8892d2a9-f92c-4ba5-82fe-684cbef51c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1625db2e-9bc0-40ef-92f2-d004af4b687e",
   "metadata": {},
   "source": [
    "# ---------------------------Testing Different Scenarios------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68e7b4-0788-45b9-b6c0-0b86b5620980",
   "metadata": {},
   "source": [
    "## TEST CASE 1: Creating Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58014e0e-7031-47d7-b357-cfe640fb7be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_learning_resource\n",
      "Categorizing the customer query further...\n",
      "Category: tutorial_agent\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDefaultCredentialsError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mI want to learn Langchain and langgraph.With usage and concept. Also give coding example implementation for both.Create tutorial for this.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mrun_user_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m result\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrun_user_query\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_user_query\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Process a user query through the LangGraph workflow.\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03m        Dict[str, str]: A dictionary containing the query's category and response\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     results = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m: results[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     14\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1844\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1843\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m1844\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1845\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1849\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1850\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1852\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1853\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1854\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1573\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1567\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1568\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   1569\u001b[39m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1570\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1571\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   1572\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1573\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1574\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1575\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1576\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1577\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1578\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1579\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1580\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1581\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:104\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    102\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, writer)\u001b[39m\n\u001b[32m     38\u001b[39m task.writes.clear()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:410\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m context.run(_set_config_context, config)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    412\u001b[39m     \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    183\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtutorial_agent\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     22\u001b[39m prompt = ChatPromptTemplate.from_messages([(\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, system_message),\n\u001b[32m     23\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mplaceholder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{chat_history}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m     24\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m     25\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mplaceholder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{agent_scratchpad}\u001b[39;00m\u001b[33m\"\u001b[39m),])\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m#agent_scratchpad is a function that formats the intermediate steps of the agent's actions and observations into a string. \u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#This function is used to keep track of the agent's thoughts or actions during the execution of the program. But its not necessary, we can do without this so we will not include it only define it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m learning_agent = \u001b[43mLearningResourceAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m path = learning_agent.TutorialAgent(state[\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     30\u001b[39m show_md_file(path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mLearningResourceAgent.__init__\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Initialize the chat model, prompt template, and search tools\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mChatGoogleGenerativeAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-pro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mself\u001b[39m.prompt = prompt\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mself\u001b[39m.tools = [DuckDuckGoSearchResults()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:881\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    879\u001b[39m         google_api_key = \u001b[38;5;28mself\u001b[39m.google_api_key\n\u001b[32m    880\u001b[39m transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28mself\u001b[39m.transport\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mgenaix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_generative_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[38;5;28mself\u001b[39m.async_client_running = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\langchain_google_genai\\_genai_extension.py:276\u001b[39m, in \u001b[36mbuild_generative_service\u001b[39m\u001b[34m(credentials, api_key, client_options, client_info, transport)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_generative_service\u001b[39m(\n\u001b[32m    263\u001b[39m     credentials: Optional[credentials.Credentials] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    264\u001b[39m     api_key: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     transport: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    268\u001b[39m ) -> v1betaGenerativeServiceClient:\n\u001b[32m    269\u001b[39m     config = _prepare_config(\n\u001b[32m    270\u001b[39m         credentials=credentials,\n\u001b[32m    271\u001b[39m         api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    274\u001b[39m         client_info=client_info,\n\u001b[32m    275\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mv1betaGenerativeServiceClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:667\u001b[39m, in \u001b[36mGenerativeServiceClient.__init__\u001b[39m\u001b[34m(self, credentials, transport, client_options, client_info)\u001b[39m\n\u001b[32m    658\u001b[39m     transport_init: Union[\n\u001b[32m    659\u001b[39m         Type[GenerativeServiceTransport],\n\u001b[32m    660\u001b[39m         Callable[..., GenerativeServiceTransport],\n\u001b[32m   (...)\u001b[39m\u001b[32m    664\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[..., GenerativeServiceTransport], transport)\n\u001b[32m    665\u001b[39m     )\n\u001b[32m    666\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport = \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33masync\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._transport):\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER.isEnabledFor(\n\u001b[32m    681\u001b[39m         std_logging.DEBUG\n\u001b[32m    682\u001b[39m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:235\u001b[39m, in \u001b[36mGenerativeServiceGrpcTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[39m\n\u001b[32m    230\u001b[39m             \u001b[38;5;28mself\u001b[39m._ssl_channel_credentials = grpc.ssl_channel_credentials(\n\u001b[32m    231\u001b[39m                 certificate_chain=cert, private_key=key\n\u001b[32m    232\u001b[39m             )\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m=\u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._grpc_channel:\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[32m    248\u001b[39m     channel_init = channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).create_channel\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\base.py:100\u001b[39m, in \u001b[36mGenerativeServiceTransport.__init__\u001b[39m\u001b[34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[39m\n\u001b[32m     96\u001b[39m     credentials, _ = google.auth.load_credentials_from_file(\n\u001b[32m     97\u001b[39m         credentials_file, **scopes_kwargs, quota_project_id=quota_project_id\n\u001b[32m     98\u001b[39m     )\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ignore_credentials:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     credentials, _ = \u001b[43mgoogle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquota_project_id\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[33m\"\u001b[39m\u001b[33mwith_gdch_audience\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\ResumeATS\\venv\\Lib\\site-packages\\google\\auth\\_default.py:685\u001b[39m, in \u001b[36mdefault\u001b[39m\u001b[34m(scopes, request, quota_project_id, default_scopes)\u001b[39m\n\u001b[32m    677\u001b[39m             _LOGGER.warning(\n\u001b[32m    678\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mNo project ID could be determined. Consider running \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    679\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    680\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33menvironment variable\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    681\u001b[39m                 environment_vars.PROJECT,\n\u001b[32m    682\u001b[39m             )\n\u001b[32m    683\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exceptions.DefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[31mDefaultCredentialsError\u001b[39m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "query = \"I want to learn Langchain and langgraph.With usage and concept. Also give coding example implementation for both.Create tutorial for this.\"\n",
    "result = run_user_query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a3631-1467-4847-9368-dffc5a9ebf91",
   "metadata": {},
   "source": [
    "## TEST CASE 2: Q&A session for Doubts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "7c780ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_learning_resource\n",
      "Categorizing the customer query further...\n",
      "Category: ask_query_bot\n",
      "\n",
      "Starting the Q&A session. Type 'exit' to end the session.\n",
      "\n",
      "**************************************************AGENT**************************************************\n",
      "\n",
      "EXPERT AGENT RESPONSE: Let's break down the differences between LangGraph and CrewAI and when you might choose one over the other for agent creation. They target slightly different needs and approaches within the broader field of generative AI-powered agents.\n",
      "\n",
      "**LangGraph (LangChain + Graph Databases):**\n",
      "\n",
      "* **Focus:** Building agents that interact with and reason over knowledge graphs or other structured data sources. LangChain itself is a framework for developing LLM applications, and incorporating a graph database adds a powerful way to represent and query relationships between entities.\n",
      "* **Strengths:**\n",
      "    * **Complex Reasoning:** Excels when your agent needs to understand and navigate relationships between different pieces of information.  Think about scenarios like knowledge exploration, question answering over a specific dataset, or tasks requiring multi-hop reasoning.\n",
      "    * **Explainability:** The structured nature of a graph database can offer better explainability for the agent's decisions. It can trace back the reasoning path through the graph.\n",
      "    * **Data Grounding:** Prevents hallucinations by anchoring the agent's responses to the facts stored in the graph.\n",
      "* **Weaknesses:**\n",
      "    * **Setup Complexity:**  Requires setting up and managing a graph database, which adds complexity compared to simpler approaches.\n",
      "    * **Data Dependence:**  The agent's knowledge is limited to what's in the graph.  It might struggle with information not represented in the graph structure.\n",
      "    * **Less Flexible for Free-Form Conversation:** While possible, adapting LangGraph for highly dynamic, open-ended conversations can be more challenging than using tools designed specifically for dialogue.\n",
      "\n",
      "\n",
      "**CrewAI:**\n",
      "\n",
      "* **Focus:** Building conversational agents and bots, especially for task-oriented dialogues.  It emphasizes the flow of conversation and integrating with various APIs and tools.\n",
      "* **Strengths:**\n",
      "    * **Ease of Use for Conversational Flows:** Provides a more streamlined experience for designing conversational flows and handling user interactions.\n",
      "    * **Tool Integration:**  Facilitates connecting your agent to external services (e.g., booking systems, databases, APIs) to perform actions within the conversation.\n",
      "    * **Multi-Agent Collaboration:** CrewAI supports the development of multiple agents that can collaborate on a task, which can be powerful for complex workflows.\n",
      "* **Weaknesses:**\n",
      "    * **Less Suitable for Complex Reasoning:**  While you can implement some logic, CrewAI is not primarily designed for deep reasoning over complex knowledge structures like a graph database.\n",
      "    * **Potential for Hallucinations:**  Relies more heavily on LLMs, which can be prone to generating incorrect or nonsensical information if not carefully managed.\n",
      "    * **Less Emphasis on Explainability:**  Tracing the reasoning behind an agent's actions might be more difficult compared to a graph-based approach.\n",
      "\n",
      "\n",
      "**In short:**\n",
      "\n",
      "* **Choose LangGraph (LangChain + Graph DB) if:** Your application requires complex reasoning over structured data, explainability is crucial, and you want to minimize hallucinations by grounding responses to a knowledge base.\n",
      "* **Choose CrewAI if:** You need to build a conversational agent for task-oriented dialogues, integrate with various tools and APIs, and potentially orchestrate multiple agents.\n",
      "\n",
      "\n",
      "Could you tell me more about the specific agent you're trying to build? Knowing the context will allow me to give you more tailored advice.  For example, what is the agent's purpose, what kind of data will it interact with, and what are the key functionalities you're aiming for?\n",
      "\n",
      "**************************************************USER**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOUR QUERY:  I want to create my Custom AI Agents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************AGENT**************************************************\n",
      "\n",
      "EXPERT AGENT RESPONSE: Creating your own custom AI agents is an exciting endeavor! To give you the best advice, let's refine our understanding of your goals.  \"Custom AI agents\" is a broad term.  Here's a breakdown of key considerations and how they might influence your tool choices:\n",
      "\n",
      "**1. Purpose and Functionality:**\n",
      "\n",
      "* **What is the agent's primary goal?**  Examples: Answering questions, performing tasks, generating creative content, controlling a game character, analyzing data, etc.\n",
      "* **What specific tasks will it perform?**  Be as detailed as possible. For example, if it's a customer service agent, list the types of customer queries it should handle.\n",
      "* **What level of autonomy are you aiming for?** Will the agent operate completely independently, or will there be human oversight?\n",
      "\n",
      "**2. Data and Knowledge:**\n",
      "\n",
      "* **What data will the agent need access to?**  Examples:  A specific knowledge base, a database, real-time data streams, files, APIs, etc.\n",
      "* **How structured is this data?**  Is it neatly organized in a database, or is it unstructured text?\n",
      "* **Will the agent need to learn and update its knowledge over time?**\n",
      "\n",
      "**3. Interaction and Interface:**\n",
      "\n",
      "* **How will users interact with the agent?**  Through a chat interface, voice commands, a graphical interface, API calls, etc.?\n",
      "* **What is the desired level of natural language understanding (NLU)?** Does it need to handle complex language, or are simple commands sufficient?\n",
      "* **Does the agent need to generate natural language responses?**\n",
      "\n",
      "**4. Development Platform and Tools:**\n",
      "\n",
      "* **What is your level of programming expertise?** Are you comfortable with Python and other relevant libraries?\n",
      "* **What resources are available to you?**  Computational power, cloud services, existing datasets, etc.\n",
      "\n",
      "\n",
      "**Example Scenarios and Tool Recommendations:**\n",
      "\n",
      "Let's illustrate with some examples:\n",
      "\n",
      "* **Scenario 1:  A research assistant that can answer questions based on a collection of scientific papers.**\n",
      "    * **Likely Tools:** LangChain with a vector database (e.g., Pinecone, Weaviate) to store embeddings of the papers.  This allows for semantic search and retrieval of relevant information.\n",
      "* **Scenario 2:  A customer service chatbot for a website.**\n",
      "    * **Likely Tools:**  Dialogflow, Rasa, or Botpress. These platforms specialize in building conversational agents and provide tools for managing dialogue flows.\n",
      "* **Scenario 3:  An agent that can automate tasks in a software application.**\n",
      "    * **Likely Tools:**  LangChain with integrations to the specific software APIs.  You might also consider tools like Microsoft's Power Automate or Zapier for simpler automations.\n",
      "* **Scenario 4:  An AI agent that plays a character in a text-based game.**\n",
      "    * **Likely Tools:**  LangChain, with a focus on prompt engineering to guide the agent's behavior and personality.\n",
      "\n",
      "\n",
      "Once you provide me with more details about your specific needs, I can give you more targeted advice on the best tools and approaches for building your custom AI agent.\n",
      "\n",
      "**************************************************USER**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOUR QUERY:  I think i understand now. Thanks for help\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************AGENT**************************************************\n",
      "\n",
      "EXPERT AGENT RESPONSE: You're welcome! I'm glad I could help clarify things.  Please don't hesitate to reach out if you have any more questions as you progress with your AI agent development.  Even a small detail about your project can often lead to more specific and helpful recommendations.  Good luck!\n",
      "\n",
      "**************************************************USER**************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOUR QUERY:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the chat session.\n",
      "File 'Agent_output\\Q&A_Doubt_Session_20241117150253.md' created successfully.\n",
      "Q&A Session saved to Agent_output\\Q&A_Doubt_Session_20241117150253.md\n",
      "{'category': 'Category: Question\\n', 'response': 'Agent_output\\\\Q&A_Doubt_Session_20241117150253.md'}\n"
     ]
    }
   ],
   "source": [
    "query = \"I am confused between Langgraph and CrewAI when to use what for Agent Creation?\"\n",
    "result = run_user_query(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88c7a5-8e78-4098-9b10-03e2ec550ca6",
   "metadata": {},
   "source": [
    "## TEST CASE 3: Interview Question Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "ba349db1-fd86-4ea4-89e7-b9ecedbecbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_interview_preparation\n",
      "Categorizing the customer query further...\n",
      "Category: interview_topics_questions\n",
      "\n",
      "Starting the Interview question preparation. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo best tailor interview questions for Generative AI job roles, I need some more information.  Please tell me:\n",
      "\n",
      "1. **What specific role are we targeting?** (e.g., Research Scientist, Machine Learning Engineer, Product Manager, Software Engineer focusing on Generative AI)  The questions will differ significantly depending on the role.\n",
      "\n",
      "2. **What is the seniority level?** (e.g., Intern, Junior, Mid-level, Senior)  The difficulty and depth of the questions should scale with experience.\n",
      "\n",
      "3. **What are the key technologies or areas of focus?** (e.g., Large Language Models (LLMs), Diffusion Models, Generative Adversarial Networks (GANs), specific applications like image generation, text generation, code generation)\n",
      "\n",
      "Once I have this information, I can generate a more relevant and effective set of interview questions.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  For Mid-level,LLM and Gen AI other techs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Interview question preparation. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOkay, focusing on a **Mid-level** role with expertise in **LLMs** and other **Generative AI technologies**, here's a markdown file containing interview questions.  This covers a range of topics, from foundational knowledge to practical application and problem-solving.  Remember that the specific questions asked should be adapted based on the candidate's resume and the specific needs of the role.\n",
      "\n",
      "\n",
      "```markdown\n",
      "# Generative AI Interview Questions - Mid-Level\n",
      "\n",
      "This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies.\n",
      "\n",
      "\n",
      "## I. Foundational Knowledge\n",
      "\n",
      "1. **Explain the difference between autoregressive and diffusion models.  Give examples of each and discuss their strengths and weaknesses.**  (Tests understanding of core model architectures)\n",
      "\n",
      "2. **Describe the Transformer architecture.  Explain the role of self-attention and positional encoding.** (Tests understanding of the backbone of many LLMs)\n",
      "\n",
      "3. **What are some common challenges in training LLMs? Discuss methods for mitigating these challenges (e.g., overfitting, vanishing gradients, computational cost).** (Tests practical experience and problem-solving skills)\n",
      "\n",
      "4. **Explain the concept of attention mechanisms. How do they improve upon previous sequence-to-sequence models?** (Tests understanding of a key component of LLMs)\n",
      "\n",
      "5. **What are different ways to evaluate the performance of a generative model? Discuss both quantitative and qualitative metrics.** (Tests understanding of evaluation methodologies)\n",
      "\n",
      "\n",
      "## II.  LLM Specifics\n",
      "\n",
      "1. **Explain the concept of prompt engineering.  Provide examples of effective prompting techniques and discuss their impact on model output.** (Tests practical experience with LLMs)\n",
      "\n",
      "2. **Describe different methods for fine-tuning LLMs for specific tasks.  Discuss the trade-offs between different approaches.** (Tests knowledge of adaptation techniques)\n",
      "\n",
      "3. **What are some common biases found in LLMs?  How can these biases be mitigated during training or deployment?** (Tests awareness of ethical considerations)\n",
      "\n",
      "4. **Discuss different methods for handling long context lengths in LLMs. What are the limitations and potential solutions?** (Tests understanding of scalability challenges)\n",
      "\n",
      "5. **Compare and contrast different LLM architectures (e.g., GPT, BERT, LaMDA). What are their strengths and weaknesses for different applications?** (Tests broad knowledge of LLM landscape)\n",
      "\n",
      "\n",
      "## III.  Other Generative AI Technologies\n",
      "\n",
      "1. **Explain the concept of Generative Adversarial Networks (GANs).  Describe the roles of the generator and discriminator.** (Tests understanding of a different generative model architecture)\n",
      "\n",
      "2. **Describe the process of generating images using diffusion models.  What are the advantages and disadvantages compared to GANs?** (Tests knowledge of another generative model)\n",
      "\n",
      "3. **Discuss the ethical implications of generative AI, including potential for misuse and bias amplification.** (Tests awareness of responsible AI development)\n",
      "\n",
      "\n",
      "## IV.  Practical Application and Problem Solving\n",
      "\n",
      "1. **Describe a project where you used generative AI to solve a real-world problem.  What were the challenges, and how did you overcome them?** (Tests practical experience and problem-solving abilities â€“ this should be a detailed discussion)\n",
      "\n",
      "2. **Design a system for generating realistic human faces using generative AI.  Discuss the technical challenges and potential solutions.** (Tests ability to design a generative AI system)\n",
      "\n",
      "3. **You are tasked with improving the efficiency of an existing LLM.  Describe your approach, considering factors such as computational resources, model size, and performance metrics.** (Tests practical problem-solving skills)\n",
      "\n",
      "4. **How would you approach debugging a generative model that is producing nonsensical or low-quality outputs?** (Tests practical troubleshooting skills)\n",
      "\n",
      "\n",
      "## V.  System Design and Deployment\n",
      "\n",
      "1.  **Design a system for deploying an LLM as an API.  Consider aspects such as scalability, latency, and security.** (Tests understanding of deployment considerations)\n",
      "\n",
      "2. **Discuss strategies for monitoring and maintaining the performance of a deployed generative AI model.** (Tests understanding of model lifecycle management)\n",
      "\n",
      "\n",
      "This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Can you give me questions for Langchain and Langgraph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Interview question preparation. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOkay, let's add some questions specifically targeting Langchain and LangGraph to the existing interview questions.  We'll integrate them into the existing markdown structure.  Since LangChain and LangGraph are relatively new, the questions will focus on understanding their core concepts and how they relate to broader Generative AI principles.\n",
      "\n",
      "\n",
      "```markdown\n",
      "# Generative AI Interview Questions - Mid-Level\n",
      "\n",
      "This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies, including LangChain and LangGraph.\n",
      "\n",
      "\n",
      "## I. Foundational Knowledge\n",
      "\n",
      "[Existing questions from previous response]\n",
      "\n",
      "\n",
      "## II.  LLM Specifics\n",
      "\n",
      "[Existing questions from previous response]\n",
      "\n",
      "\n",
      "## III.  Other Generative AI Technologies\n",
      "\n",
      "[Existing questions from previous response]\n",
      "\n",
      "\n",
      "## IV. LangChain and LangGraph\n",
      "\n",
      "1. **What is LangChain, and what are its key components?  Describe how it simplifies the development of LLM-powered applications.** (Tests understanding of LangChain's core functionality)\n",
      "\n",
      "2. **Explain the concept of chains and agents in LangChain.  Provide examples of how they can be used to build complex LLM applications.** (Tests understanding of LangChain's architectural patterns)\n",
      "\n",
      "3. **How does LangChain handle memory in LLM applications?  Discuss different memory types and their use cases.** (Tests understanding of state management in LangChain)\n",
      "\n",
      "4. **Describe how you would use LangChain to build an application that integrates multiple LLMs or other tools (e.g., databases, APIs).** (Tests ability to apply LangChain in a practical scenario)\n",
      "\n",
      "5. **What is LangGraph? How does it differ from other knowledge graph approaches, and what are its advantages and disadvantages for building LLM applications?** (Tests understanding of LangGraph's unique features)\n",
      "\n",
      "6. **How can LangGraph be used to enhance the capabilities of LLMs?  Provide specific examples of how it improves reasoning, knowledge access, or context management.** (Tests understanding of LangGraph's applications)\n",
      "\n",
      "7. **Compare and contrast LangChain and LangGraph.  Discuss scenarios where one might be preferred over the other.** (Tests ability to compare and contrast different tools)\n",
      "\n",
      "8. **Describe a potential project where you would utilize both LangChain and LangGraph to build a sophisticated LLM-powered application.  Outline the architecture and key components.** (Tests ability to design a complex system using both tools)\n",
      "\n",
      "\n",
      "## V.  Practical Application and Problem Solving\n",
      "\n",
      "[Existing questions from previous response]\n",
      "\n",
      "\n",
      "## VI.  System Design and Deployment\n",
      "\n",
      "[Existing questions from previous response]\n",
      "\n",
      "\n",
      "This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Interview question preparation. Type 'exit' to end the session.\n",
      "\n",
      "Ending the conversation. Goodbye!\n",
      "File 'Agent_output\\Interview_questions_20241117151913.md' created successfully.\n",
      "Interviews question saved to Agent_output\\Interview_questions_20241117151913.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To best tailor interview questions for Generative AI job roles, I need some more information.  Please tell me:\n",
       "\n",
       "1. **What specific role are we targeting?** (e.g., Research Scientist, Machine Learning Engineer, Product Manager, Software Engineer focusing on Generative AI)  The questions will differ significantly depending on the role.\n",
       "\n",
       "2. **What is the seniority level?** (e.g., Intern, Junior, Mid-level, Senior)  The difficulty and depth of the questions should scale with experience.\n",
       "\n",
       "3. **What are the key technologies or areas of focus?** (e.g., Large Language Models (LLMs), Diffusion Models, Generative Adversarial Networks (GANs), specific applications like image generation, text generation, code generation)\n",
       "\n",
       "Once I have this information, I can generate a more relevant and effective set of interview questions.\n",
       "Okay, focusing on a **Mid-level** role with expertise in **LLMs** and other **Generative AI technologies**, here's a markdown file containing interview questions.  This covers a range of topics, from foundational knowledge to practical application and problem-solving.  Remember that the specific questions asked should be adapted based on the candidate's resume and the specific needs of the role.\n",
       "\n",
       "\n",
       "\n",
       "# Generative AI Interview Questions - Mid-Level\n",
       "\n",
       "This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies.\n",
       "\n",
       "\n",
       "## I. Foundational Knowledge\n",
       "\n",
       "1. **Explain the difference between autoregressive and diffusion models.  Give examples of each and discuss their strengths and weaknesses.**  (Tests understanding of core model architectures)\n",
       "\n",
       "2. **Describe the Transformer architecture.  Explain the role of self-attention and positional encoding.** (Tests understanding of the backbone of many LLMs)\n",
       "\n",
       "3. **What are some common challenges in training LLMs? Discuss methods for mitigating these challenges (e.g., overfitting, vanishing gradients, computational cost).** (Tests practical experience and problem-solving skills)\n",
       "\n",
       "4. **Explain the concept of attention mechanisms. How do they improve upon previous sequence-to-sequence models?** (Tests understanding of a key component of LLMs)\n",
       "\n",
       "5. **What are different ways to evaluate the performance of a generative model? Discuss both quantitative and qualitative metrics.** (Tests understanding of evaluation methodologies)\n",
       "\n",
       "\n",
       "## II.  LLM Specifics\n",
       "\n",
       "1. **Explain the concept of prompt engineering.  Provide examples of effective prompting techniques and discuss their impact on model output.** (Tests practical experience with LLMs)\n",
       "\n",
       "2. **Describe different methods for fine-tuning LLMs for specific tasks.  Discuss the trade-offs between different approaches.** (Tests knowledge of adaptation techniques)\n",
       "\n",
       "3. **What are some common biases found in LLMs?  How can these biases be mitigated during training or deployment?** (Tests awareness of ethical considerations)\n",
       "\n",
       "4. **Discuss different methods for handling long context lengths in LLMs. What are the limitations and potential solutions?** (Tests understanding of scalability challenges)\n",
       "\n",
       "5. **Compare and contrast different LLM architectures (e.g., GPT, BERT, LaMDA). What are their strengths and weaknesses for different applications?** (Tests broad knowledge of LLM landscape)\n",
       "\n",
       "\n",
       "## III.  Other Generative AI Technologies\n",
       "\n",
       "1. **Explain the concept of Generative Adversarial Networks (GANs).  Describe the roles of the generator and discriminator.** (Tests understanding of a different generative model architecture)\n",
       "\n",
       "2. **Describe the process of generating images using diffusion models.  What are the advantages and disadvantages compared to GANs?** (Tests knowledge of another generative model)\n",
       "\n",
       "3. **Discuss the ethical implications of generative AI, including potential for misuse and bias amplification.** (Tests awareness of responsible AI development)\n",
       "\n",
       "\n",
       "## IV.  Practical Application and Problem Solving\n",
       "\n",
       "1. **Describe a project where you used generative AI to solve a real-world problem.  What were the challenges, and how did you overcome them?** (Tests practical experience and problem-solving abilities â€“ this should be a detailed discussion)\n",
       "\n",
       "2. **Design a system for generating realistic human faces using generative AI.  Discuss the technical challenges and potential solutions.** (Tests ability to design a generative AI system)\n",
       "\n",
       "3. **You are tasked with improving the efficiency of an existing LLM.  Describe your approach, considering factors such as computational resources, model size, and performance metrics.** (Tests practical problem-solving skills)\n",
       "\n",
       "4. **How would you approach debugging a generative model that is producing nonsensical or low-quality outputs?** (Tests practical troubleshooting skills)\n",
       "\n",
       "\n",
       "## V.  System Design and Deployment\n",
       "\n",
       "1.  **Design a system for deploying an LLM as an API.  Consider aspects such as scalability, latency, and security.** (Tests understanding of deployment considerations)\n",
       "\n",
       "2. **Discuss strategies for monitoring and maintaining the performance of a deployed generative AI model.** (Tests understanding of model lifecycle management)\n",
       "\n",
       "\n",
       "This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.\n",
       "```\n",
       "Okay, let's add some questions specifically targeting Langchain and LangGraph to the existing interview questions.  We'll integrate them into the existing markdown structure.  Since LangChain and LangGraph are relatively new, the questions will focus on understanding their core concepts and how they relate to broader Generative AI principles.\n",
       "\n",
       "\n",
       "\n",
       "# Generative AI Interview Questions - Mid-Level\n",
       "\n",
       "This document outlines interview questions for a mid-level Generative AI role, encompassing expertise in LLMs and other generative AI technologies, including LangChain and LangGraph.\n",
       "\n",
       "\n",
       "## I. Foundational Knowledge\n",
       "\n",
       "[Existing questions from previous response]\n",
       "\n",
       "\n",
       "## II.  LLM Specifics\n",
       "\n",
       "[Existing questions from previous response]\n",
       "\n",
       "\n",
       "## III.  Other Generative AI Technologies\n",
       "\n",
       "[Existing questions from previous response]\n",
       "\n",
       "\n",
       "## IV. LangChain and LangGraph\n",
       "\n",
       "1. **What is LangChain, and what are its key components?  Describe how it simplifies the development of LLM-powered applications.** (Tests understanding of LangChain's core functionality)\n",
       "\n",
       "2. **Explain the concept of chains and agents in LangChain.  Provide examples of how they can be used to build complex LLM applications.** (Tests understanding of LangChain's architectural patterns)\n",
       "\n",
       "3. **How does LangChain handle memory in LLM applications?  Discuss different memory types and their use cases.** (Tests understanding of state management in LangChain)\n",
       "\n",
       "4. **Describe how you would use LangChain to build an application that integrates multiple LLMs or other tools (e.g., databases, APIs).** (Tests ability to apply LangChain in a practical scenario)\n",
       "\n",
       "5. **What is LangGraph? How does it differ from other knowledge graph approaches, and what are its advantages and disadvantages for building LLM applications?** (Tests understanding of LangGraph's unique features)\n",
       "\n",
       "6. **How can LangGraph be used to enhance the capabilities of LLMs?  Provide specific examples of how it improves reasoning, knowledge access, or context management.** (Tests understanding of LangGraph's applications)\n",
       "\n",
       "7. **Compare and contrast LangChain and LangGraph.  Discuss scenarios where one might be preferred over the other.** (Tests ability to compare and contrast different tools)\n",
       "\n",
       "8. **Describe a potential project where you would utilize both LangChain and LangGraph to build a sophisticated LLM-powered application.  Outline the architecture and key components.** (Tests ability to design a complex system using both tools)\n",
       "\n",
       "\n",
       "## V.  Practical Application and Problem Solving\n",
       "\n",
       "[Existing questions from previous response]\n",
       "\n",
       "\n",
       "## VI.  System Design and Deployment\n",
       "\n",
       "[Existing questions from previous response]\n",
       "\n",
       "\n",
       "This list is not exhaustive, and the specific questions asked should be tailored to the candidate's experience and the requirements of the role.  Remember to also assess soft skills such as communication, teamwork, and problem-solving abilities throughout the interview process.\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'Category: Question\\n', 'response': 'Agent_output\\\\Interview_questions_20241117151913.md'}\n"
     ]
    }
   ],
   "source": [
    "query = \"I want to discussion Interview question for Gen AI job roles.\"\n",
    "result = run_user_query(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd628e-730b-4627-a8c6-e00a6022a54a",
   "metadata": {},
   "source": [
    "## TEST CASE 4: Mock Interview with Evaluation Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "728b6877-9383-470f-ad01-2c7e5705593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_interview_preparation\n",
      "Categorizing the customer query further...\n",
      "Category: mock_interview\n",
      "\n",
      "Starting the mock interview. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "Interviewer: Great! Welcome.  My name is Alex, and I'll be conducting your interview today for the Generative AI Engineer position.  Let's start with a brief introduction from you. Tell me about yourself and your experience relevant to this role.  We have your resume, but I'd like to hear it in your own words.  Keep it to about 2-3 minutes.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate:  Iâ€™m Karan, and Iâ€™m currently focused on advancing my skills and contributions in Generative AI. My journey started with a solid foundation in Computer Science, where I developed a strong interest in AI and machine learning. Over the years, Iâ€™ve built a range of projects that have helped me gain expertise in several core areas of this role.  One of my most impactful experiences was working on an end-to-end Legal Case Identification system for Verinext and Pondlehocky. This project involved integrating Gen-AI to automate case assignments. I led a team to develop a pipeline that included NLP, GPT, prompt engineering, and Litify DB integration, ultimately enabling efficient case handling through an AI-driven model.  Iâ€™ve also worked on an Automatic Number Plate Recognition project for NPCI. This required designing and deploying a real-time ANPR solution using transfer learning, Deepstream, and OCR. I collaborated closely with my team on model improvement and pipeline optimization to ensure the project could effectively replace existing toll services.  Beyond my technical skills, I bring a strategic approach to problem-solving and a knack for diving into the nuances of machine learning models, optimizing them to fit specific business needs. Iâ€™m passionate about harnessing AI to address real-world challenges, and Iâ€™m excited about the possibility of contributing my skills and learning further with your team.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: That's a strong introduction, Karan.  Your projects demonstrate a good understanding of the practical applications of Generative AI. Let's delve a bit deeper.  You mentioned prompt engineering in your Legal Case Identification project. Can you describe a challenging prompt engineering problem you faced and how you solved it?  What metrics did you use to evaluate the success of your prompt engineering efforts?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate:  Certainly, Alex.  In the Legal Case Identification project, a significant challenge in prompt engineering arose when trying to accurately classify complex case types from unstructured legal data. The prompts needed to be crafted carefully to balance specificity with flexibility, as the language in legal documents can vary widely. One particular issue was handling nuanced legal terms and context-specific language that often influenced the interpretation of a caseâ€™s category.  To address this, I experimented with structured prompt templates that included both contextual keywords and specific qualifiers. For example, rather than just asking the model to classify a \"personal injury\" case, I structured prompts to include additional context like, \"Identify if this case involves physical harm due to an accident or negligence,\" which guided the model to focus on relevant legal scenarios.  For evaluation, I used precision, recall, and F1 scores to measure how accurately the prompts identified cases correctly across categories. Additionally, we monitored the modelâ€™s consistency by testing it on a set of challenging cases with subtle differences to see if the prompts led to consistent responses. I also tracked user feedback from legal experts who verified if the classifications aligned with practical expectations.  This iterative approach, along with close collaboration with subject matter experts, allowed me to refine prompts effectively. It was a great learning experience in balancing prompt detail and adaptability while ensuring reliable, high-quality results for the client.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: Excellent.  That demonstrates a good understanding of prompt engineering and evaluation metrics.  Now, let's shift gears slightly.  Generative AI models can sometimes produce biased or inaccurate outputs.  How would you address such issues in a production environment?\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate:  Thank you, Alex; thatâ€™s an important consideration.  In a production environment, handling bias and inaccuracies in Generative AI outputs requires a proactive, multi-layered approach. Hereâ€™s how Iâ€™d approach it:  Data and Model Auditing: Iâ€™d start by auditing the training data to identify and mitigate any inherent biases. This might involve using a diverse dataset or adding counterexamples to balance the perspectives presented in the modelâ€™s outputs. Model fine-tuning can help adjust any biases found in pre-trained models by focusing on more representative or neutral datasets.  Prompt Design and Constraints: In prompt engineering, Iâ€™d craft prompts that guide the model toward neutral and accurate responses. For instance, setting constraints in the prompt to avoid speculative or potentially biased language can help. Additionally, Iâ€™d use prompt templates that explicitly frame questions to elicit factual and context-appropriate information.  Post-Processing and Filtering: After generating outputs, Iâ€™d implement a filtering or post-processing layer that flags any content that seems potentially biased or incorrect. For example, sentiment analysis or bias detection algorithms can help flag outputs, allowing for an additional layer of human review or correction before the final output is published.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: Good.  You've covered some key aspects.  One last question:  Describe your preferred approach to staying up-to-date with the rapidly evolving field of Generative AI.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate:  To stay current in Generative AI, I rely on a structured approach that combines both learning from established resources and exploring emerging trends:  Research Papers and Journals: I regularly read papers from sources like arXiv and conferences such as NeurIPS, ICML, and CVPR. Following key researchers and institutions helps me stay updated on cutting-edge techniques, and I make it a habit to read and analyze at least one new paper each week, focusing on both theoretical advances and practical applications.  Community and Open-Source Contributions: I participate in open-source projects on platforms like GitHub, which keeps me connected with the latest tools and libraries. Additionally, contributing to or following repositories in frameworks like Hugging Face or PyTorch gives me hands-on exposure to practical advancements in model development and deployment.  Online Courses and Workshops: I engage in online courses or certifications, especially when new architectures or methodologies gain traction, such as diffusion models or prompt engineering techniques. Platforms like Coursera and specialized workshops provide structured, in-depth content that complements hands-on experience.  Podcasts and Newsletters: I subscribe to AI-focused newsletters like \"The Batch\" by Andrew Ng and listen to podcasts such as \"Lex Fridman\" and \"Data Skeptic,\" which often feature industry experts discussing the latest trends and breakthroughs. This is a great way to get a broader perspective on AI developments and practical applications.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: Excellent. Thank you, Karan. That concludes our interview.  I appreciate you taking the time to speak with me today.\n",
      "\n",
      "\n",
      "**Evaluation:**\n",
      "\n",
      "Karan demonstrated a strong understanding of Generative AI concepts and their practical application. His project descriptions were detailed and showcased his ability to tackle complex problems and evaluate results effectively.  He articulated a well-rounded approach to addressing bias and maintaining accuracy in production environments. His commitment to continuous learning is also commendable. While he could have provided more specific examples in some areas, overall, he presented himself as a strong candidate for the Generative AI Engineer position.  I would recommend him for the next stage of the interview process.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the interview session.\n",
      "File 'Agent_output\\Mock_Interview_20241117174111.md' created successfully.\n",
      "Mock Interview saved to Agent_output\\Mock_Interview_20241117174111.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Candidate: I am ready for the interview.\n",
       " \n",
       "\n",
       "Interviewer: Great! Welcome.  My name is Alex, and I'll be conducting your interview today for the Generative AI Engineer position.  Let's start with a brief introduction from you. Tell me about yourself and your experience relevant to this role.  We have your resume, but I'd like to hear it in your own words.  Keep it to about 2-3 minutes.\n",
       " \n",
       "\n",
       "Candidate: Iâ€™m Karan, and Iâ€™m currently focused on advancing my skills and contributions in Generative AI. My journey started with a solid foundation in Computer Science, where I developed a strong interest in AI and machine learning. Over the years, Iâ€™ve built a range of projects that have helped me gain expertise in several core areas of this role.  One of my most impactful experiences was working on an end-to-end Legal Case Identification system for Verinext and Pondlehocky. This project involved integrating Gen-AI to automate case assignments. I led a team to develop a pipeline that included NLP, GPT, prompt engineering, and Litify DB integration, ultimately enabling efficient case handling through an AI-driven model.  Iâ€™ve also worked on an Automatic Number Plate Recognition project for NPCI. This required designing and deploying a real-time ANPR solution using transfer learning, Deepstream, and OCR. I collaborated closely with my team on model improvement and pipeline optimization to ensure the project could effectively replace existing toll services.  Beyond my technical skills, I bring a strategic approach to problem-solving and a knack for diving into the nuances of machine learning models, optimizing them to fit specific business needs. Iâ€™m passionate about harnessing AI to address real-world challenges, and Iâ€™m excited about the possibility of contributing my skills and learning further with your team. \n",
       "\n",
       "Interviewer: That's a strong introduction, Karan.  Your projects demonstrate a good understanding of the practical applications of Generative AI. Let's delve a bit deeper.  You mentioned prompt engineering in your Legal Case Identification project. Can you describe a challenging prompt engineering problem you faced and how you solved it?  What metrics did you use to evaluate the success of your prompt engineering efforts?\n",
       " \n",
       "\n",
       "Candidate: Certainly, Alex.  In the Legal Case Identification project, a significant challenge in prompt engineering arose when trying to accurately classify complex case types from unstructured legal data. The prompts needed to be crafted carefully to balance specificity with flexibility, as the language in legal documents can vary widely. One particular issue was handling nuanced legal terms and context-specific language that often influenced the interpretation of a caseâ€™s category.  To address this, I experimented with structured prompt templates that included both contextual keywords and specific qualifiers. For example, rather than just asking the model to classify a \"personal injury\" case, I structured prompts to include additional context like, \"Identify if this case involves physical harm due to an accident or negligence,\" which guided the model to focus on relevant legal scenarios.  For evaluation, I used precision, recall, and F1 scores to measure how accurately the prompts identified cases correctly across categories. Additionally, we monitored the modelâ€™s consistency by testing it on a set of challenging cases with subtle differences to see if the prompts led to consistent responses. I also tracked user feedback from legal experts who verified if the classifications aligned with practical expectations.  This iterative approach, along with close collaboration with subject matter experts, allowed me to refine prompts effectively. It was a great learning experience in balancing prompt detail and adaptability while ensuring reliable, high-quality results for the client. \n",
       "\n",
       "Interviewer: Excellent.  That demonstrates a good understanding of prompt engineering and evaluation metrics.  Now, let's shift gears slightly.  Generative AI models can sometimes produce biased or inaccurate outputs.  How would you address such issues in a production environment?\n",
       "\n",
       "\n",
       " \n",
       "\n",
       "Candidate: Thank you, Alex; thatâ€™s an important consideration.  In a production environment, handling bias and inaccuracies in Generative AI outputs requires a proactive, multi-layered approach. Hereâ€™s how Iâ€™d approach it:  Data and Model Auditing: Iâ€™d start by auditing the training data to identify and mitigate any inherent biases. This might involve using a diverse dataset or adding counterexamples to balance the perspectives presented in the modelâ€™s outputs. Model fine-tuning can help adjust any biases found in pre-trained models by focusing on more representative or neutral datasets.  Prompt Design and Constraints: In prompt engineering, Iâ€™d craft prompts that guide the model toward neutral and accurate responses. For instance, setting constraints in the prompt to avoid speculative or potentially biased language can help. Additionally, Iâ€™d use prompt templates that explicitly frame questions to elicit factual and context-appropriate information.  Post-Processing and Filtering: After generating outputs, Iâ€™d implement a filtering or post-processing layer that flags any content that seems potentially biased or incorrect. For example, sentiment analysis or bias detection algorithms can help flag outputs, allowing for an additional layer of human review or correction before the final output is published. \n",
       "\n",
       "Interviewer: Good.  You've covered some key aspects.  One last question:  Describe your preferred approach to staying up-to-date with the rapidly evolving field of Generative AI.\n",
       "\n",
       " \n",
       "\n",
       "Candidate: To stay current in Generative AI, I rely on a structured approach that combines both learning from established resources and exploring emerging trends:  Research Papers and Journals: I regularly read papers from sources like arXiv and conferences such as NeurIPS, ICML, and CVPR. Following key researchers and institutions helps me stay updated on cutting-edge techniques, and I make it a habit to read and analyze at least one new paper each week, focusing on both theoretical advances and practical applications.  Community and Open-Source Contributions: I participate in open-source projects on platforms like GitHub, which keeps me connected with the latest tools and libraries. Additionally, contributing to or following repositories in frameworks like Hugging Face or PyTorch gives me hands-on exposure to practical advancements in model development and deployment.  Online Courses and Workshops: I engage in online courses or certifications, especially when new architectures or methodologies gain traction, such as diffusion models or prompt engineering techniques. Platforms like Coursera and specialized workshops provide structured, in-depth content that complements hands-on experience.  Podcasts and Newsletters: I subscribe to AI-focused newsletters like \"The Batch\" by Andrew Ng and listen to podcasts such as \"Lex Fridman\" and \"Data Skeptic,\" which often feature industry experts discussing the latest trends and breakthroughs. This is a great way to get a broader perspective on AI developments and practical applications. \n",
       "\n",
       "Interviewer: Excellent. Thank you, Karan. That concludes our interview.  I appreciate you taking the time to speak with me today.\n",
       "\n",
       "\n",
       "**Evaluation:**\n",
       "\n",
       "Karan demonstrated a strong understanding of Generative AI concepts and their practical application. His project descriptions were detailed and showcased his ability to tackle complex problems and evaluate results effectively.  He articulated a well-rounded approach to addressing bias and maintaining accuracy in production environments. His commitment to continuous learning is also commendable. While he could have provided more specific examples in some areas, overall, he presented himself as a strong candidate for the Generative AI Engineer position.  I would recommend him for the next stage of the interview process.\n",
       " \n",
       "\n",
       "Candidate: exit \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Category: Mock\\n',\n",
       " 'response': 'Agent_output\\\\Mock_Interview_20241117174111.md'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the conversation. Goodbye!\n",
      "File 'Agent_output\\Interview_questions_20241117005746.md' created successfully.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To best help you prepare for your Generative AI interview, I need some more information.  Please tell me:\n",
       "\n",
       "1. **What is your target role?** (e.g., Research Scientist, Software Engineer, Product Manager, etc.)  The questions will vary significantly depending on the role.\n",
       "\n",
       "2. **What is your experience level?** (e.g., Intern, Junior, Mid-level, Senior)  This will help tailor the difficulty of the questions.\n",
       "\n",
       "3. **Which specific Generative AI areas are you most familiar with?** (e.g., Large Language Models, Diffusion Models, Generative Adversarial Networks, etc.)  Focusing on your strengths will maximize your chances of success.\n",
       "\n",
       "4. **Are there any specific companies or teams you're interviewing with?** Knowing the company's focus can help me tailor the questions to their specific interests.\n",
       "\n",
       "\n",
       "Once I have this information, I can generate a list of relevant interview questions and potential answers, along with references and links to helpful resources.  I will organize this into a markdown (.md) file.\n",
       "Okay, given that you're a mid-level Generative AI Engineer focusing on LLMs, GANs, NLP, and ML, I can create a tailored set of interview questions.  I will categorize them for clarity.  Note that some questions may touch upon multiple areas.  I won't provide complete answers here, as that would be too extensive, but I'll give you pointers to guide your preparation.\n",
       "\n",
       "\n",
       "# Generative AI Engineer Interview Questions (Mid-Level)\n",
       "\n",
       "This document outlines potential interview questions for a mid-level Generative AI Engineer role, focusing on LLMs, GANs, NLP, and ML.  Remember to tailor your answers to your specific experiences and projects.\n",
       "\n",
       "## I. Large Language Models (LLMs)\n",
       "\n",
       "**A. Foundational Understanding:**\n",
       "\n",
       "1. **Explain the architecture of a Transformer network.  Discuss the role of self-attention and its computational complexity.**  *(Focus on encoder-decoder structure, attention mechanisms, positional encoding, and computational challenges like quadratic complexity with naive attention.)*\n",
       "\n",
       "2. **Compare and contrast different LLM architectures (e.g., GPT, BERT, T5).  Highlight their strengths and weaknesses for different tasks.** *(Consider differences in training objectives, autoregressive vs. masked language modeling, and suitability for various NLP tasks.)*\n",
       "\n",
       "3. **What are some common challenges in training LLMs? Discuss methods to mitigate issues like vanishing gradients, overfitting, and catastrophic forgetting.** *(Address gradient clipping, regularization techniques, transfer learning, and continual learning strategies.)*\n",
       "\n",
       "\n",
       "**B. Advanced Topics & Applications:**\n",
       "\n",
       "4. **Describe different methods for prompting LLMs to improve performance and control the generated text.  Give examples of few-shot, zero-shot, and chain-of-thought prompting.** *(Discuss prompt engineering techniques, including various prompting strategies and their effectiveness.)*\n",
       "\n",
       "5. **Explain how reinforcement learning can be used to fine-tune LLMs.  Discuss the role of reward models and algorithms like Proximal Policy Optimization (PPO).** *(Focus on RLHF (Reinforcement Learning from Human Feedback) and its application in aligning LLMs with human preferences.)*\n",
       "\n",
       "6. **Discuss the ethical considerations surrounding LLMs, such as bias, toxicity, and misinformation.  How can these issues be addressed?** *(Consider bias mitigation techniques, safety guidelines, and responsible AI practices.)*\n",
       "\n",
       "7. **Describe your experience with specific LLM frameworks (e.g., Hugging Face Transformers, TensorFlow, PyTorch).** *(Highlight your practical experience with these frameworks and any relevant projects.)*\n",
       "\n",
       "\n",
       "## II. Generative Adversarial Networks (GANs)\n",
       "\n",
       "**A. Core Concepts:**\n",
       "\n",
       "1. **Explain the architecture and training process of a GAN. Describe the roles of the generator and discriminator.** *(Focus on the minimax game, backpropagation, and the adversarial training process.)*\n",
       "\n",
       "2. **What are some common problems encountered when training GANs (e.g., mode collapse, vanishing gradients)?  How can these be addressed?** *(Discuss techniques like Wasserstein GANs (WGANs), gradient penalty, and spectral normalization.)*\n",
       "\n",
       "3. **Compare and contrast different GAN architectures (e.g., DCGAN, StyleGAN, CycleGAN).  Discuss their applications and advantages.** *(Highlight architectural differences and their impact on generated output quality and diversity.)*\n",
       "\n",
       "\n",
       "**B. Advanced Topics & Applications:**\n",
       "\n",
       "4. **Explain how GANs can be used for image generation, image-to-image translation, and other generative tasks.** *(Provide specific examples and discuss the effectiveness of GANs in these applications.)*\n",
       "\n",
       "5. **Describe your experience with GAN training and optimization techniques. Discuss your experience with hyperparameter tuning and model evaluation metrics.** *(Highlight your practical experience and the tools/techniques used.)*\n",
       "\n",
       "\n",
       "## III. Natural Language Processing (NLP) and Machine Learning (ML)\n",
       "\n",
       "**A. NLP Techniques:**\n",
       "\n",
       "1. **Describe different NLP techniques used in preprocessing text data (e.g., tokenization, stemming, lemmatization).** *(Explain the purpose and impact of each technique.)*\n",
       "\n",
       "2. **Explain various word embedding techniques (e.g., Word2Vec, GloVe, FastText).  Discuss their strengths and weaknesses.** *(Focus on the underlying algorithms and their representational capabilities.)*\n",
       "\n",
       "3. **Discuss different sequence-to-sequence models and their applications in machine translation and text summarization.** *(Explain the encoder-decoder architecture and its use in these tasks.)*\n",
       "\n",
       "\n",
       "**B. ML Fundamentals:**\n",
       "\n",
       "1. **Explain different types of machine learning algorithms (e.g., supervised, unsupervised, reinforcement learning).** *(Provide examples and discuss their use cases.)*\n",
       "\n",
       "2. **Describe different model evaluation metrics (e.g., precision, recall, F1-score, AUC).** *(Explain the meaning and interpretation of these metrics.)*\n",
       "\n",
       "3. **Discuss your experience with model deployment and monitoring.** *(Highlight your practical experience in deploying models to production environments.)*\n",
       "\n",
       "\n",
       "## IV.  Project & Experience Based Questions\n",
       "\n",
       "1. **Describe a challenging project you worked on involving generative AI.  What were the key challenges, and how did you overcome them?**  *(Focus on a project that showcases your technical skills and problem-solving abilities.)*\n",
       "\n",
       "2. **Discuss your experience with version control (e.g., Git) and collaborative development.** *(Highlight your teamwork skills and experience with collaborative tools.)*\n",
       "\n",
       "3. **How do you stay up-to-date with the latest advancements in generative AI?** *(Discuss your approach to continuous learning and staying current in the field.)*\n",
       "\n",
       "\n",
       "This comprehensive list should provide a strong foundation for your interview preparation. Remember to practice explaining your projects and technical concepts clearly and concisely. Good luck!\n",
       "Let's focus on a few crucial topics and provide more detailed answers, keeping in mind the mid-level Generative AI Engineer role and your expertise in LLMs, GANs, NLP, and ML.  Remember that these are examples, and your answers should reflect your own experiences and understanding.\n",
       "\n",
       "**I.  LLMs:  Addressing Bias in LLMs**\n",
       "\n",
       "**Question:**  \"Large language models are known to exhibit biases present in their training data.  Describe several techniques used to mitigate bias in LLMs, and discuss their limitations.\"\n",
       "\n",
       "**Answer:**  \"Mitigating bias in LLMs is a complex and ongoing challenge.  Several strategies exist, each with limitations:\n",
       "\n",
       "* **Data Preprocessing:** Carefully curating the training data to remove or rebalance biased content.  This is resource-intensive and might not completely eliminate subtle biases.  Furthermore, identifying and removing all biased content is very difficult.\n",
       "\n",
       "* **Algorithmic Mitigation:**  Techniques like adversarial training can be employed.  This involves training a separate model to identify and counteract bias during the LLM's training.  However, designing effective adversarial training methods is challenging, and it's difficult to ensure complete bias removal.\n",
       "\n",
       "* **Post-Processing Techniques:**  These methods filter or modify the LLM's output after generation to reduce bias.  Examples include re-ranking generated responses based on fairness metrics or using classifiers to identify and flag biased text.  The drawback is that these methods might impact the fluency or coherence of the generated text.\n",
       "\n",
       "* **Reinforcement Learning from Human Feedback (RLHF):**  This approach involves training a reward model that ranks responses based on their fairness and lack of bias.  The LLM is then fine-tuned using this reward model via reinforcement learning. While effective, it requires significant human effort to create and evaluate the reward model, and human biases can still creep in.\n",
       "\n",
       "* **Fairness-Aware Metrics:**  Developing and using metrics that specifically quantify bias in LLM outputs is crucial.  This allows for better monitoring and evaluation of bias mitigation techniques.  However, designing truly comprehensive and unbiased metrics remains an area of active research.\n",
       "\n",
       "In summary, mitigating bias in LLMs is a multifaceted problem requiring a combination of approaches.  No single technique is a silver bullet, and continuous research is necessary to develop more effective and robust methods.\"\n",
       "\n",
       "\n",
       "**II. GANs:  Mode Collapse and its Solutions**\n",
       "\n",
       "**Question:** \"Explain the phenomenon of 'mode collapse' in GAN training.  Describe at least three different techniques to mitigate mode collapse.\"\n",
       "\n",
       "**Answer:** \"Mode collapse in GANs occurs when the generator learns to produce only a limited set of outputs, failing to capture the full diversity of the data distribution.  This results in the generator producing similar samples repeatedly, even when the input noise varies.  Several methods address this:\n",
       "\n",
       "* **Improved Architectures:**  Using architectures like Wasserstein GANs (WGANs) or improved versions like WGAN-GP (WGAN with Gradient Penalty) often helps.  These methods use different loss functions that encourage the discriminator to provide more informative gradients, thus preventing the generator from getting stuck in local optima.\n",
       "\n",
       "* **Regularization Techniques:**  Applying regularization techniques such as spectral normalization to the discriminator or weight clipping in WGANs can stabilize training and reduce mode collapse.  These methods constrain the discriminator's behavior, preventing it from becoming too powerful and overwhelming the generator.\n",
       "\n",
       "* **Mini-batch Discrimination:**  This technique involves feeding mini-batches of generated samples to the discriminator simultaneously.  This allows the discriminator to compare generated samples with each other, encouraging the generator to produce more diverse outputs.\n",
       "\n",
       "* **Label Smoothing:**  Adding noise to the discriminator's labels during training can help improve the stability of training and reduce mode collapse.\n",
       "\n",
       "* **Two Timescale Update Rule (TTUR):** This method uses different learning rates for the generator and the discriminator, often leading to more stable training dynamics.\n",
       "\n",
       "\n",
       "The choice of technique often depends on the specific GAN architecture and dataset.  A combination of methods is often most effective.\"\n",
       "\n",
       "\n",
       "**III. NLP & ML:  Explainable AI (XAI) in NLP**\n",
       "\n",
       "**Question:** \"Explain the importance of explainable AI (XAI) in NLP, particularly in the context of LLMs.  Describe some techniques used to make NLP models more interpretable.\"\n",
       "\n",
       "**Answer:** \"Explainability is crucial in NLP, especially with complex models like LLMs, because it increases trust, facilitates debugging, and allows for better model understanding and improvement.  Opaque models make it difficult to identify biases, errors, or unexpected behaviors.  Several techniques promote interpretability:\n",
       "\n",
       "* **Attention Mechanisms:**  Analyzing the attention weights in Transformer networks provides insights into which parts of the input sequence the model focuses on when generating output.  This can reveal the model's reasoning process.\n",
       "\n",
       "* **Saliency Maps:**  These highlight the input features that most influence the model's prediction.  In NLP, this could show which words or phrases are most important for a particular classification or generation task.\n",
       "\n",
       "* **Feature Importance Analysis:**  Techniques like SHAP (SHapley Additive exPlanations) or LIME (Local Interpretable Model-agnostic Explanations) can be used to quantify the contribution of individual features (words, phrases, etc.) to the model's prediction.\n",
       "\n",
       "* **Rule Extraction:**  For simpler models, rules can be extracted directly from the model's parameters, providing a more explicit representation of the model's decision-making process.\n",
       "\n",
       "* **Probing Classifiers:**  Training separate classifiers to predict specific aspects of the model's internal representations can reveal what information the model learns and how it uses it.\n",
       "\n",
       "\n",
       "While these methods offer insights, perfect explainability is often challenging to achieve, especially with highly complex models.  The choice of technique depends on the specific model and the desired level of interpretability.\"\n",
       "\n",
       "\n",
       "These expanded answers provide a more thorough response to common interview questions.  Remember to adapt them to your own experiences and projects.  Good luck!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'Category: Question\\n',\n",
       " 'response': 'Agent_output\\\\Interview_questions_20241117005746.md'}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I need mock interview to practice.\"\n",
    "result = run_user_query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc89a57-2c6e-4cff-a1e5-44a461df813a",
   "metadata": {},
   "source": [
    "## TEST CASE 5: Resume Modification Based on Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "987566c5-0db8-4033-9fa5-da939dd2f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_resume_making\n",
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can definitely help you with that! To tailor your resume effectively, I'll need some information from you. First, could you please share:\n",
      "\n",
      "1. Your current resume (in any format).\n",
      "2. The job description of the role you're targeting.\n",
      "3. Your LinkedIn profile URL (optional).\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  SKILLS:   Technical skills:   â€¢ Demonstrated work experience with natural language processing techniques to drive business value. Experience building user-centric AI products/features is highly valuable.    â€¢ Knowledge in Hypothesis testing, Statistical Methods, Sampling Theory, Experimental Design    â€¢ Familiarity with common advanced analysis tools â€“ SQL & Python/R    â€¢ Demonstrated familiarity (work experience, GitHub account) with OOP concepts. Expertise in Python is a big plus.    â€¢ Experience with cloud computing (AWS) & MLOps is a plus.    â€¢ Strong knowledge of Machine Learning & Deep Learning   Soft/Leadership skills:   â€¢ Use business acumen and analytical skills to identify opportunities, estimate potential, layout strategy roadmaps to solve complex business problems.    â€¢ Be motivated to explore and identify opportunities from scratch by thinking backwards on problem solving by putting users and data at the center of analysis and decision making.    â€¢ Be responsible for using analytical techniques like Machine learning, Natural Language Processing, and advanced data visualizations to improve Asurionâ€™s customersâ€™ experiences.    â€¢ Deploy ML solutions in production environment    â€¢ Design statistical tests for product experiments, measure impact, derive insights and provide recommendations    â€¢ Work closely with product managers to identify and answer important product questions that help improve outcomes      Resume: KARAN SHRESTHA LinkedIn | 747-295-9996 | ks.karanshrestha@gmail.com | GitHub Seasoned Data Scientist skilled in Python, Machine Learning, NLP, and Deep Learning, Generative AI, Prompt Engineering with 4.5 years of experience. Proven ability in data science, excellent communication skills, and analytical skills. Effective team player with strong time management. Keen learner with a proactive attitude. Skills ____________________________________________________________________________________________ â€¢ Python | SQL | C# | Tensorflow | Pytorch | Numpy | NLTK | Pandas | Natural Language Processing | Machine Learning| Database query | â€¢ Computer Vision | Transformers | MXNet | Deep Learning | Anomaly detection | Scikit-learn | CNN | RNN | LSTM -Neural networks | â€¢ AWS | JavaScript | REST API | LLMs-Large Language Models | Keras | Predictive Modeling | Generative AI | Prompt Engineering | Neo4j â€¢ Tableau | Power BI | Fine Tuning | Problem solving | Web Development | PySpark | GCP | Azure | Statistics | Statistical modeling | R Experience _______________________________________________________________________________________ Senior Data Scientist FreightMango Gurgaon, India 06/2023 â€“ 12/2023 â€¢ Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models. â€¢ Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models. â€¢ Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%. â€¢ Drive the vision of the product, ensuring alignment with business goals. Implement networking protocols and ensure robust product security. Conducted research to identify industry trends, applying findings to product innovation. â€¢ Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models. â€¢ Developed ML models and maintained information systems to manage and process large data sets, ensuring data integrity and availability for machine learning projects. â€¢ Demonstrated a high level of attention to detail in data preprocessing, model tuning, and system optimization, ensuring accuracy and reliability in deliverables. â€¢ Collaborate with cross-functional teams to develop innovative solutions. Apply analytical skills to solve complex problems and improve basic functionalities. Managed social media campaigns, boosting engagement by 30% with targeted content strategies. Software Engineer DataNova Noida, India 02/2019 - 06/2023 â€¢ Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects. â€¢ Feature Engineering and created data visualizations to support data-driven decisions. Execute on design, build, analysis and validation of  data analytics, modeling, and machine learning techniques â€¢ In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms. â€¢ Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP. â€¢ Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object  Detection. â€¢ Developed predictive models using algorithms such as Kernel-KNN, Decision Trees, Random Forest, Gradient Boosting, SVMs, and XgBoost. â€¢ Ensure scalability, security, and performance of the applications. Conduct thorough testing and monitoring to ensure high-quality deliverables. Developed and executed strategic plans, driving growth and improving efficiency. â€¢ Engage in code review processes to maintain code quality and best practices. Utilize metrics and analytics to measure and improve product performance. Created and refined project specifications to align with client requirements and industry standards. â€¢ Developed innovative machine learning solutions and computer vision models, significantly enhancing system performance and accuracy. â€¢ Contribute to the development of ML models and their integration into the product. Provide written and verbal communication on project progress and technical issues. â€¢ Regularly monitored the status of machine learning models and data pipelines, ensuring optimal performance and accuracy through continuous evaluation and fine-tuning. Education ________________________________________________________________________________________ Master of Science San Francisco Bay University Fremont, CA, USA 01/2024 - Present â€¢ Major in Computer Science (3.93 GPA) Bachelor of Science ITS Engineering College Greater Noida, India 05/2015 - 06/2019 â€¢ Major in Computer Science & Engineering (3.62 GPA) Projects __________________________________________________________________________________________ â€¢ WAFER SENSOR FAULT CLASSIFICATION: Predict the quality of the wafer whether good or bad based on the different sensor values for each wafer. A wafer is a thin semiconductor used in various electronic devices. Technology: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K Means++ Clustering, Classification, Hyperparameter tuning. â€¢ HAND DETECTION-Shredder Machine: Detect the hands of the workers working with the shredder machine and stop the machine if hands come near the machine to prevent injury. Technology: Python, SQL, Tensorflow object detection framework-SSDlite â€¢ ANPR (Automatic Number Plate Recognition): Worked on end-to-end ANPR for NPCI , installed on Mumbai Marine Lines running on real time. ANPR is Automatic Number Plate Recognition system , Purpose for this Solution is to replace Fastag and convert all toll services with ANPR solution. Technology: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, paddel, dbnet, OCR(CRNN, paddel OCR,tensorRT), ML-Flow, Python, OpenCV, Pandas. â€¢ VERINEXT(PondLehocky) on Project Legal-Case-Identification (LCI): LCI( Legal-Case-Identification) is a legal domain project , This Solution is for US legal firms to replace their Manual processes to assign case to suitable handling firm with Gen-AI solution with Littify DB. Technology: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API , Litify, Deep learning Algo, AZURE-API. â€¢ FM QUOTATION REQUEST - OCR: A fully automated OCR model that takes input as a pdf or doc file scans it and retrieves information regarding quotation of the user for delivery and pick up details of requests and process it. Technology: Natural Language Processing, Spacy, NER, Data cleaning. â€¢ CONCRETE STRENGTH PREDICTION: A regression model to predict the concrete compressive strength based on quantity of different components of mixtures and cement. Technology: Python,SQL, Machine learning, XGboost Regressor, Data Validation, Preprocessing, Clustering, Hyperparameter tuning. â€¢ WEBSHOP-CUSTOMER REVIEWS SENTIMENTS: Classifies the reviews of all the customers visited in Web-Shop and gives the different sentiment analysis reports. Technology: NLP, Naive bayes, Support Vector machine, TFIDF, SQL. Mentorship _______________________________________________________________________________________ â€¢ Data Science Tutor: Programming | Data Science | Machine Learning | Data Visualization. Certificates ___________________________________________________________________________________________ â€¢ Oracle Cloud Infrastructure 2024 Generative AI Certified Professional. Link â€¢ Gold Badge (5 Star) for Python on HackerRank. Link â€¢ Data Scientist 1 year Master Professional Program. Link â€¢ Certificate of Training in MACHINE LEARNING Advance course. Link\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```markdown\n",
      "# Karan Shrestha\n",
      "[LinkedIn](LinkedIn) | 747-295-9996 | ks.karanshrestha@gmail.com | [GitHub](GitHub)\n",
      "\n",
      "## Summary\n",
      "\n",
      "Highly motivated and results-oriented Data Scientist with 4.5 years of experience specializing in Machine Learning, Natural Language Processing (NLP), Deep Learning, Generative AI, and Prompt Engineering. Proven ability to leverage data-driven insights to solve complex business problems, with a strong focus on building user-centric AI products. Expertise in Python, cloud computing (AWS), and MLOps, along with excellent communication and teamwork skills.  Passionate about exploring and identifying opportunities to improve customer experiences through innovative AI solutions.\n",
      "\n",
      "## Skills\n",
      "\n",
      "**Technical Skills:** Python, SQL, C#, TensorFlow, PyTorch, NumPy, NLTK, Pandas, Scikit-learn, Transformers, MXNet, Keras, Deep Learning, CNN, RNN, LSTM, Computer Vision, Anomaly Detection, AWS, JavaScript, REST API, LLMs (Large Language Models), Generative AI, Prompt Engineering, Fine-tuning, PySpark, GCP, Azure,  Statistics, Statistical Modeling, R, Neo4j\n",
      "\n",
      "**Soft/Leadership Skills:**  Problem-solving, Business Acumen, Analytical Skills, Strategic Planning, Communication (Written & Verbal), Teamwork, Time Management,  Product Vision, Cross-functional Collaboration, Data Visualization (Tableau, Power BI)\n",
      "\n",
      "\n",
      "## Experience\n",
      "\n",
      "**Senior Data Scientist, FreightMango, Gurgaon, India (06/2023 â€“ 12/2023)**\n",
      "\n",
      "* Engineered an automated customer quotation document scanning pipeline using OCR and NLP, resulting in a 40% increase in customer acquisition.\n",
      "* Applied Machine Learning (ML) algorithms to optimize finance-related applications, improving the accuracy and efficiency of financial forecasting models.\n",
      "* Developed and maintained information systems for managing and processing large datasets for machine learning projects.\n",
      "* Conducted research on industry trends and applied findings to product innovation, driving the product vision and ensuring alignment with business goals.\n",
      "* Implemented networking protocols and ensured robust product security.\n",
      "* Collaborated with cross-functional teams to develop innovative solutions and improve core functionalities.\n",
      "* Managed social media campaigns, increasing engagement by 30% through targeted content strategies.\n",
      "\n",
      "**Software Engineer, DataNova, Noida, India (02/2019 - 06/2023)**\n",
      "\n",
      "* Developed and delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.\n",
      "* Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like object detection.\n",
      "* Developed predictive models using algorithms such as Kernel-KNN, Decision Trees, Random Forest, Gradient Boosting, SVMs, and XGBoost.\n",
      "* Conducted image annotation, text data cleaning, text vectorization, and data preprocessing for machine learning projects.\n",
      "* Created data visualizations to support data-driven decisions.\n",
      "* Contributed to the development of ML models and their integration into the product.\n",
      "* Regularly monitored and fine-tuned machine learning models and data pipelines to ensure optimal performance and accuracy.\n",
      "\n",
      "\n",
      "## Education\n",
      "\n",
      "**Master of Science in Computer Science (3.93 GPA), San Francisco Bay University, Fremont, CA, USA (01/2024 â€“ Present)**\n",
      "\n",
      "**Bachelor of Science in Computer Science & Engineering (3.62 GPA), ITS Engineering College, Greater Noida, India (05/2015 - 06/2019)**\n",
      "\n",
      "\n",
      "## Projects\n",
      "\n",
      "* **Wafer Sensor Fault Classification:** Developed a machine learning model using Random Forest Classifier and K-Means++ Clustering to predict wafer quality based on sensor data.\n",
      "* **Hand Detection - Shredder Machine:** Implemented a real-time hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent workplace injuries.\n",
      "* **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI using computer vision, transfer learning, and deep learning techniques.\n",
      "* **Verinext (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Gen-AI solution using NLP, GPT, and Prompt Engineering to automate legal case assignments.\n",
      "* **FM Quotation Request - OCR:** Built an automated OCR model using NLP and Spacy to extract information from quotation documents and streamline the request process.\n",
      "* **Concrete Strength Prediction:** Developed a regression model using XGBoost Regressor to predict concrete compressive strength based on mixture components.\n",
      "* **Webshop - Customer Reviews Sentiments:** Implemented a sentiment analysis model using NLP techniques to classify customer reviews and generate reports.\n",
      "\n",
      "## Mentorship\n",
      "\n",
      "* **Data Science Tutor:** Provided tutoring in Programming, Data Science, Machine Learning, and Data Visualization.\n",
      "\n",
      "## Certifications\n",
      "\n",
      "* **Oracle Cloud Infrastructure 2024 Generative AI Certified Professional:** [Link](Link)\n",
      "* **Gold Badge (5 Star) for Python on HackerRank:** [Link]\n",
      "* **Data Scientist 1-year Master Professional Program:** [Link]\n",
      "* **Certificate of Training in Machine Learning Advanced Course:** [Link]\n",
      "\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "Ending the conversation. Goodbye!\n",
      "File 'Agent_output\\Resume_20241117173459.md' created successfully.\n",
      "Resume saved to Agent_output\\Resume_20241117173459.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Karan Shrestha\n",
       "[LinkedIn](LinkedIn) | 747-295-9996 | ks.karanshrestha@gmail.com | [GitHub](GitHub)\n",
       "\n",
       "## Summary\n",
       "\n",
       "Highly motivated and results-oriented Data Scientist with 4.5 years of experience specializing in Machine Learning, Natural Language Processing (NLP), Deep Learning, Generative AI, and Prompt Engineering. Proven ability to leverage data-driven insights to solve complex business problems, with a strong focus on building user-centric AI products. Expertise in Python, cloud computing (AWS), and MLOps, along with excellent communication and teamwork skills.  Passionate about exploring and identifying opportunities to improve customer experiences through innovative AI solutions.\n",
       "\n",
       "## Skills\n",
       "\n",
       "**Technical Skills:** Python, SQL, C#, TensorFlow, PyTorch, NumPy, NLTK, Pandas, Scikit-learn, Transformers, MXNet, Keras, Deep Learning, CNN, RNN, LSTM, Computer Vision, Anomaly Detection, AWS, JavaScript, REST API, LLMs (Large Language Models), Generative AI, Prompt Engineering, Fine-tuning, PySpark, GCP, Azure,  Statistics, Statistical Modeling, R, Neo4j\n",
       "\n",
       "**Soft/Leadership Skills:**  Problem-solving, Business Acumen, Analytical Skills, Strategic Planning, Communication (Written & Verbal), Teamwork, Time Management,  Product Vision, Cross-functional Collaboration, Data Visualization (Tableau, Power BI)\n",
       "\n",
       "\n",
       "## Experience\n",
       "\n",
       "**Senior Data Scientist, FreightMango, Gurgaon, India (06/2023 â€“ 12/2023)**\n",
       "\n",
       "* Engineered an automated customer quotation document scanning pipeline using OCR and NLP, resulting in a 40% increase in customer acquisition.\n",
       "* Applied Machine Learning (ML) algorithms to optimize finance-related applications, improving the accuracy and efficiency of financial forecasting models.\n",
       "* Developed and maintained information systems for managing and processing large datasets for machine learning projects.\n",
       "* Conducted research on industry trends and applied findings to product innovation, driving the product vision and ensuring alignment with business goals.\n",
       "* Implemented networking protocols and ensured robust product security.\n",
       "* Collaborated with cross-functional teams to develop innovative solutions and improve core functionalities.\n",
       "* Managed social media campaigns, increasing engagement by 30% through targeted content strategies.\n",
       "\n",
       "**Software Engineer, DataNova, Noida, India (02/2019 - 06/2023)**\n",
       "\n",
       "* Developed and delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.\n",
       "* Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like object detection.\n",
       "* Developed predictive models using algorithms such as Kernel-KNN, Decision Trees, Random Forest, Gradient Boosting, SVMs, and XGBoost.\n",
       "* Conducted image annotation, text data cleaning, text vectorization, and data preprocessing for machine learning projects.\n",
       "* Created data visualizations to support data-driven decisions.\n",
       "* Contributed to the development of ML models and their integration into the product.\n",
       "* Regularly monitored and fine-tuned machine learning models and data pipelines to ensure optimal performance and accuracy.\n",
       "\n",
       "\n",
       "## Education\n",
       "\n",
       "**Master of Science in Computer Science (3.93 GPA), San Francisco Bay University, Fremont, CA, USA (01/2024 â€“ Present)**\n",
       "\n",
       "**Bachelor of Science in Computer Science & Engineering (3.62 GPA), ITS Engineering College, Greater Noida, India (05/2015 - 06/2019)**\n",
       "\n",
       "\n",
       "## Projects\n",
       "\n",
       "* **Wafer Sensor Fault Classification:** Developed a machine learning model using Random Forest Classifier and K-Means++ Clustering to predict wafer quality based on sensor data.\n",
       "* **Hand Detection - Shredder Machine:** Implemented a real-time hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent workplace injuries.\n",
       "* **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI using computer vision, transfer learning, and deep learning techniques.\n",
       "* **Verinext (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Gen-AI solution using NLP, GPT, and Prompt Engineering to automate legal case assignments.\n",
       "* **FM Quotation Request - OCR:** Built an automated OCR model using NLP and Spacy to extract information from quotation documents and streamline the request process.\n",
       "* **Concrete Strength Prediction:** Developed a regression model using XGBoost Regressor to predict concrete compressive strength based on mixture components.\n",
       "* **Webshop - Customer Reviews Sentiments:** Implemented a sentiment analysis model using NLP techniques to classify customer reviews and generate reports.\n",
       "\n",
       "## Mentorship\n",
       "\n",
       "* **Data Science Tutor:** Provided tutoring in Programming, Data Science, Machine Learning, and Data Visualization.\n",
       "\n",
       "## Certifications\n",
       "\n",
       "* **Oracle Cloud Infrastructure 2024 Generative AI Certified Professional:** [Link](Link)\n",
       "* **Gold Badge (5 Star) for Python on HackerRank:** [Link]\n",
       "* **Data Scientist 1-year Master Professional Program:** [Link]\n",
       "* **Certificate of Training in Machine Learning Advanced Course:** [Link]\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'category': '2\\n', 'response': 'Agent_output\\\\Resume_20241117173459.md'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Can you help me to modify my resume based on job description\"\n",
    "result = run_user_query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032b1b8-641e-4fff-a816-a0254be1a4c1",
   "metadata": {},
   "source": [
    "## TEST CASE 6: Resume Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e967ff9-f878-4eb8-ab33-a478ab5f0fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: handle_resume_making\n",
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can definitely help you with that! To create a tailored resume for Generative AI roles, I need some information from you.  Could you please tell me about your technical skills related to AI/ML and Generative AI in particular?  For example, list specific programming languages, platforms, libraries, and tools you're proficient in (e.g., Python, TensorFlow, PyTorch, Transformers, LangChain, etc.).\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Skills ____________________________________________________________________________________________ â€¢ Python | SQL | C# | Tensorflow | Pytorch | Numpy | NLTK | Pandas | Natural Language Processing | Machine Learning| Database query | â€¢ Computer Vision | Transformers | MXNet | Deep Learning | Anomaly detection | Scikit-learn | CNN | RNN | LSTM -Neural networks | â€¢ AWS | JavaScript | REST API | LLMs-Large Language Models | Keras | Predictive Modeling | Generative AI | Prompt Engineering | Neo4j â€¢ Tableau | Power BI | Fine Tuning | Problem solving | Web Development | PySpark | GCP | Azure | Statistics | Statistical modeling | R\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mGreat!  Now, please tell me about your work experience and projects, focusing on those relevant to Generative AI.  For each experience/project, please provide a brief description, highlighting your contributions and the technologies used.  If you have any publications or patents, please mention those as well.  If you're a fresh graduate or have no direct experience, describe relevant academic projects or coursework.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Experience _______________________________________________________________________________________ Senior Data Scientist FreightMango Gurgaon, India 06/2023 â€“ 12/2023 â€¢ Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models. â€¢ Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models. â€¢ Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%. â€¢ Drive the vision of the product, ensuring alignment with business goals. Implement networking protocols and ensure robust product security. Conducted research to identify industry trends, applying findings to product innovation. â€¢ Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models.Software Engineer DataNova Noida, India 02/2019 - 06/2023 â€¢ Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects. â€¢ Feature Engineering and created data visualizations to support data-driven decisions. Execute on design, build, analysis and validation of  data analytics, modeling, and machine learning techniques â€¢ In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms. â€¢ Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP. â€¢ Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object  Detection.  Projects __________________________________________________________________________________________ â€¢ WAFER SENSOR FAULT CLASSIFICATION: Predict the quality of the wafer whether good or bad based on the different sensor values for each wafer. A wafer is a thin semiconductor used in various electronic devices. Technology: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K Means++ Clustering, Classification, Hyperparameter tuning. â€¢ HAND DETECTION-Shredder Machine: Detect the hands of the workers working with the shredder machine and stop the machine if hands come near the machine to prevent injury. Technology: Python, SQL, Tensorflow object detection framework-SSDlite â€¢ ANPR (Automatic Number Plate Recognition): Worked on end-to-end ANPR for NPCI , installed on Mumbai Marine Lines running on real time. ANPR is Automatic Number Plate Recognition system , Purpose for this Solution is to replace Fastag and convert all toll services with ANPR solution. Technology: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, paddel, dbnet, OCR(CRNN, paddel OCR,tensorRT), ML-Flow, Python, OpenCV, Pandas. â€¢ VERINEXT(PondLehocky) on Project Legal-Case-Identification (LCI): LCI( Legal-Case-Identification) is a legal domain project , This Solution is for US legal firms to replace their Manual processes to assign case to suitable handling firm with Gen-AI solution with Littify DB. Technology: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API , Litify, Deep learning Algo, AZURE-API.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mOkay, that's a good start.  Finally, could you please provide your education details (degrees, university, graduation dates), any relevant certifications (e.g., AWS Certified Machine Learning â€“ Specialty), and your contact information (name, phone number, email, LinkedIn profile URL if you have one)?  You can replace your actual contact information with placeholders if you prefer not to share it here.\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  Education ________________________________________________________________________________________ Master of Science San Francisco Bay University Fremont, CA, USA 01/2024 - Present â€¢ Major in Computer Science (3.93 GPA) Bachelor of Science ITS Engineering College Greater Noida, India 05/2015 - 06/2019 â€¢ Major in Computer Science & Engineering (3.62 GPA)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```markdown\n",
      "# [Your Name]\n",
      "[Phone Number] | [Email Address] | [LinkedIn Profile URL]\n",
      "\n",
      "## Summary\n",
      "\n",
      "Highly motivated and results-oriented AI Engineer with a proven track record in developing and deploying Generative AI solutions. Expertise in leveraging cutting-edge technologies like LLMs, Transformers, and Deep Learning to solve complex business problems. Passionate about building innovative and impactful AI-driven applications.\n",
      "\n",
      "## Skills\n",
      "\n",
      "**Programming Languages:** Python, SQL, C#, JavaScript, R\n",
      "**AI/ML Libraries & Frameworks:** TensorFlow, PyTorch, Keras, Scikit-learn, Transformers, LangChain, NLTK, Pandas, NumPy, MXNet\n",
      "**Cloud Platforms:** AWS, GCP, Azure\n",
      "**Databases:** SQL, Neo4j\n",
      "**Other Tools & Technologies:**  Computer Vision, CNN, RNN, LSTM, Natural Language Processing (NLP), Deep Learning, Predictive Modeling, Generative AI, Prompt Engineering, Fine-tuning, REST API, Tableau, Power BI, PySpark, Docker, Deepstream\n",
      "\n",
      "## Experience\n",
      "\n",
      "**Senior Data Scientist, FreightMango (Gurgaon, India)**  06/2023 â€“ 12/2023\n",
      "* Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%.\n",
      "* Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models.\n",
      "* Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models.\n",
      "* Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models.\n",
      "* Drove the product vision, ensuring alignment with business goals. Implemented networking protocols and ensured robust product security.\n",
      "* Conducted research to identify industry trends, applying findings to product innovation.\n",
      "\n",
      "\n",
      "**Software Engineer, DataNova (Noida, India)** 02/2019 - 06/2023\n",
      "* Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects.\n",
      "* Feature Engineering and created data visualizations to support data-driven decisions. Executed design, build, analysis and validation of data analytics, modeling, and machine learning techniques.\n",
      "* In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms.\n",
      "* Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.\n",
      "* Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object Detection.\n",
      "\n",
      "\n",
      "## Projects\n",
      "\n",
      "* **VERINEXT (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Generative AI solution for US legal firms to automate case assignment using the Littify database.  Technologies: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API, Litify, Deep learning algorithms, Azure API.\n",
      "* **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI, deployed on Mumbai Marine Lines, running in real-time, to replace Fastag and convert toll services to ANPR. Technologies: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, PaddleOCR, DBNet, OCR (CRNN, PaddleOCR, TensorRT), MLflow, Python, OpenCV, Pandas.\n",
      "* **HAND DETECTION-Shredder Machine:** Developed a hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent injuries by stopping the shredder machine when hands come near. Technologies: Python, SQL, TensorFlow Object Detection framework-SSDlite.\n",
      "* **WAFER SENSOR FAULT CLASSIFICATION:** Developed a model to predict wafer quality based on sensor values. Technologies: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K-Means++ Clustering, Classification, Hyperparameter tuning.\n",
      "\n",
      "## Education\n",
      "\n",
      "* **Master of Science in Computer Science,** San Francisco Bay University (Fremont, CA, USA)  01/2024 - Present (GPA: 3.93)\n",
      "* **Bachelor of Science in Computer Science & Engineering,** ITS Engineering College (Greater Noida, India) 05/2015 - 06/2019 (GPA: 3.62)\n",
      "\n",
      "\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting the Resume create session. Type 'exit' to end the session.\n",
      "\n",
      "Ending the conversation. Goodbye!\n",
      "File 'Agent_output\\Resume_20241117162047.md' created successfully.\n",
      "Resume saved to Agent_output\\Resume_20241117162047.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# [Your Name]\n",
       "[Phone Number] | [Email Address] | [LinkedIn Profile URL]\n",
       "\n",
       "## Summary\n",
       "\n",
       "Highly motivated and results-oriented AI Engineer with a proven track record in developing and deploying Generative AI solutions. Expertise in leveraging cutting-edge technologies like LLMs, Transformers, and Deep Learning to solve complex business problems. Passionate about building innovative and impactful AI-driven applications.\n",
       "\n",
       "## Skills\n",
       "\n",
       "**Programming Languages:** Python, SQL, C#, JavaScript, R\n",
       "**AI/ML Libraries & Frameworks:** TensorFlow, PyTorch, Keras, Scikit-learn, Transformers, LangChain, NLTK, Pandas, NumPy, MXNet\n",
       "**Cloud Platforms:** AWS, GCP, Azure\n",
       "**Databases:** SQL, Neo4j\n",
       "**Other Tools & Technologies:**  Computer Vision, CNN, RNN, LSTM, Natural Language Processing (NLP), Deep Learning, Predictive Modeling, Generative AI, Prompt Engineering, Fine-tuning, REST API, Tableau, Power BI, PySpark, Docker, Deepstream\n",
       "\n",
       "## Experience\n",
       "\n",
       "**Senior Data Scientist, FreightMango (Gurgaon, India)**  06/2023 â€“ 12/2023\n",
       "* Engineered an automated customer quotation document scanning pipeline, boosting customer acquisition by 40%.\n",
       "* Applied data preprocessing techniques, including data collection and cleaning, to prepare datasets for Machine learning models.\n",
       "* Tuned and optimized datasets through advanced data preprocessing techniques for machine learning models.\n",
       "* Applied machine learning (ML) algorithms to optimize finance-related applications, enhancing the accuracy and efficiency of financial forecasting models.\n",
       "* Drove the product vision, ensuring alignment with business goals. Implemented networking protocols and ensured robust product security.\n",
       "* Conducted research to identify industry trends, applying findings to product innovation.\n",
       "\n",
       "\n",
       "**Software Engineer, DataNova (Noida, India)** 02/2019 - 06/2023\n",
       "* Conducted image annotation, text data cleaning, text vectorization, manipulation, and data preprocessing for Machine learning projects.\n",
       "* Feature Engineering and created data visualizations to support data-driven decisions. Executed design, build, analysis and validation of data analytics, modeling, and machine learning techniques.\n",
       "* In-depth expertise with a rich repertoire of Regression, Classification, Clustering, and Dimensionality reduction algorithms.\n",
       "* Delivered pre-trained and fine-tuned neural network models using TensorFlow for internal projects, including object detection and automated chatbots using NLP.\n",
       "* Collaborated with cross-functional teams to deploy machine learning solutions, enhancing performance for perception tasks like Object Detection.\n",
       "\n",
       "\n",
       "## Projects\n",
       "\n",
       "* **VERINEXT (PondLehocky) on Project Legal-Case-Identification (LCI):** Developed a Generative AI solution for US legal firms to automate case assignment using the Littify database.  Technologies: Gen-AI, NLP, GPT, Prompt engineering, LangChain, Authentication API, Litify, Deep learning algorithms, Azure API.\n",
       "* **ANPR (Automatic Number Plate Recognition):** Developed an end-to-end ANPR system for NPCI, deployed on Mumbai Marine Lines, running in real-time, to replace Fastag and convert toll services to ANPR. Technologies: Computer vision, Transfer learning, Deepstream, Docker, GCP, Yolo, Tracker, PaddleOCR, DBNet, OCR (CRNN, PaddleOCR, TensorRT), MLflow, Python, OpenCV, Pandas.\n",
       "* **HAND DETECTION-Shredder Machine:** Developed a hand detection system using TensorFlow Object Detection framework (SSDlite) to prevent injuries by stopping the shredder machine when hands come near. Technologies: Python, SQL, TensorFlow Object Detection framework-SSDlite.\n",
       "* **WAFER SENSOR FAULT CLASSIFICATION:** Developed a model to predict wafer quality based on sensor values. Technologies: Python, SQL, Machine learning, RandomForest Classifier, Data Validation, Preprocessing, K-Means++ Clustering, Classification, Hyperparameter tuning.\n",
       "\n",
       "## Education\n",
       "\n",
       "* **Master of Science in Computer Science,** San Francisco Bay University (Fremont, CA, USA)  01/2024 - Present (GPA: 3.93)\n",
       "* **Bachelor of Science in Computer Science & Engineering,** ITS Engineering College (Greater Noida, India) 05/2015 - 06/2019 (GPA: 3.62)\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'category': '2\\n', 'response': 'Agent_output\\\\Resume_20241117162047.md'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want to make resume for Gen AI roles job.\"\n",
    "result = run_user_query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9ed5d-b29f-4030-86fc-6dd2d4f7a8c8",
   "metadata": {},
   "source": [
    "## TEST CASE 7: Job Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbe5815d-19d3-480e-81f8-2e4a97f47494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing the customer query...\n",
      "Category: job_search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to mention Job location you want,Job roles\n",
      " Find jobs in GenAI, AI Engineer roles, Location USA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'Agent_output\\Job_search_20241117172655.md' created successfully.\n",
      "Jobs saved to Agent_output\\Job_search_20241117172655.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Generative AI Engineer Job Listings\n",
       "\n",
       "This document provides a curated list of job opportunities in the field of Generative AI.\n",
       "\n",
       "## Job Listings\n",
       "\n",
       "| Title                                                                                             | Company       | Location                 | Salary Range             | Description                                                                                                                                                                                                                            | Link                                                                                                        |\n",
       "|---------------------------------------------------------------------------------------------------|---------------|--------------------------|--------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------|\n",
       "| Generative AI Engineer                                                                            | Cognizant     | Varies                  | Not specified           | Cognizant seeks an innovative Gen AI Engineer to develop cutting-edge, cloud-based software. Ideal candidates enjoy working in diverse, collaborative, geographically distributed teams and are expert engineers.                       | [Apply Here](https://careers.cognizant.com/global-en/jobs/00061676931/generative-ai-engineer/)             |\n",
       "| Staff Software Engineer, AI/ML GenAI, Gemini                                                       | Google        | US                      | $189,000-$284,000 + bonus + equity + benefits | Build a conversational AI tool that enables users to collaborate with generative AI, augmenting their imagination, expanding their curiosity, and enhancing their productivity.                                                       | [Apply Here](https://jobs.anitab.org/companies/google-24698/jobs/42530065-staff-software-engineer-ai-ml-genai-gemini) |\n",
       "| Staff Software Engineer, AI/ML GenAI, Google Cloud AI                                            | Google        | Sunnyvale, CA             | Not specified           | Join the Google Cloud AI team as a Staff Software Engineer, AI/ML GenAI. Salary ranges are determined by role, level, and location.                                                                                                       | [Apply Here](https://www.linkedin.com/jobs/view/staff-software-engineer-ai-ml-genai-google-cloud-ai-at-google-4074504841) |\n",
       "| Staff Software Engineer, AI/ML GenAI, Google Cloud AI                                            | Google        | Not specified           | Not specified           | Another listing for the same role at Google, potentially with different details.  Salary ranges are determined by role, level, and location.                                                                                              | [Apply Here](https://www.themuse.com/jobs/google/staff-software-engineer-aiml-genai-google-cloud-ai)        |\n",
       "\n",
       "\n",
       "This list is not exhaustive and may be updated periodically.  Please check the provided links for the most up-to-date information on each position."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'category': '4\\n', 'response': 'Agent_output\\\\Job_search_20241117172655.md'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I want to search jobs.\"\n",
    "\n",
    "result = run_user_query(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f75df-ebf3-4bc3-b71d-17116524146f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
